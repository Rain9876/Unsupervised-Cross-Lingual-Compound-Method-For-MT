{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from nltk import meteor_score\n",
    "# from nltk.tokenize import word_tokenize \n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.translate import meteor_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from itertools import product\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pulp\n",
    "\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all json data\n",
    "data_path = sys.path[0]+\"/human_assessment/\"\n",
    "\n",
    "with open(data_path+'MMTsourcedict.json') as json_file:\n",
    "    src_dict = json.load(json_file)\n",
    "with open(data_path+'MMTgolddict_de.json') as json_file:\n",
    "    ref_de_dict = json.load(json_file)\n",
    "with open(data_path+'MMTtranslationdict_de.json') as json_file:\n",
    "    mt_de_dict = json.load(json_file)\n",
    "with open(data_path+'MMTgolddict_fr.json') as json_file:\n",
    "    ref_fr_dict = json.load(json_file)\n",
    "with open(data_path+'MMTtranslationdict_fr.json') as json_file:\n",
    "    mt_fr_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une photo aérienne d'un paysage d'herbe brunissante avec une sorte de château culminant , et un paysage montagneux à l'horizon .\n",
      "\n",
      "une photo aérienne de seniors et d'une belle structure ressemblant à travers un paysage de montagne dans l'horizon.\n",
      "\n",
      "un paysage de signalisation, regarde de la prairie et une structure ressemblant à une structure à l'intérieur et un paysage de montagne à l'horizon.\n",
      "\n",
      "une photo de paysage aérienne d'une prairie et d'une structure ressemblant à une structure en hauteur et un paysage de montagne à l'horizon.\n",
      "\n",
      "une photo de pêcheurs aérienne de paille et d'une structure brumeuse regarde au loin et un paysage de montagne à l'horizon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_up_french(ref_fr_dict, mt_fr_dict):\n",
    "    tmp = ref_fr_dict.items()\n",
    "    for key, value in tmp:\n",
    "        new_val = re.sub(r\"&\\w+;\\s\",\"'\",value)\n",
    "        ref_fr_dict[key] = new_val\n",
    "\n",
    "    tmp = mt_fr_dict.items()\n",
    "    for key, value in tmp:\n",
    "            new_val = [[re.sub(r\"&\\w+;\\s\",\"'\",item[0]),item[1]]for item in value]\n",
    "            mt_fr_dict[key] = new_val\n",
    "    return ref_fr_dict, mt_fr_dict\n",
    "    \n",
    "ref_fr_dict, mt_fr_dict = clean_up_french(ref_fr_dict, mt_fr_dict)\n",
    "    \n",
    "\n",
    "# print(ref_fr_dict[\"30167206992.jpg\"])\n",
    "# print(mt_fr_dict[\"30167206992.jpg\"])\n",
    "\n",
    "print(ref_fr_dict[\"27124904596.jpg\"])\n",
    "print()\n",
    "for i in mt_fr_dict[\"27124904596.jpg\"]:\n",
    "    print(i[0]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# matching image id for src sent, ref sent, translation sent\n",
    "\n",
    "## Sorting if necessary\n",
    "# sorted_src_dict = {key: value for key, value in sorted(src_dict.items(), key=lambda item: item[0])}\n",
    "# ref_de_dict = {key: value for key, value in sorted(ref_de_dict.items(), key=lambda item: item[0])}\n",
    "# score_de_dict = {key: value for key, value in sorted(score_de_dict.items(), key=lambda item: item[0])}\n",
    "\n",
    "de_match = {}\n",
    "assert len(src_dict) == len(ref_de_dict)\n",
    "for src_id in src_dict:\n",
    "    if src_id in mt_de_dict and src_id in ref_de_dict:\n",
    "         de_match[src_id] = [src_dict[src_id], ref_de_dict[src_id], mt_de_dict[src_id]]\n",
    "    else:\n",
    "        de_match[src_id] = [src_dict[src_id], ref_de_dict[src_id], []] # Assign empty list for Non-score sentences\n",
    "print(len(de_match))\n",
    "\n",
    "\n",
    "fr_match = {}\n",
    "assert len(src_dict) == len(ref_fr_dict)\n",
    "for src_id in src_dict:\n",
    "    if src_id in mt_fr_dict and src_id in ref_fr_dict:\n",
    "         fr_match[src_id] = [src_dict[src_id], ref_fr_dict[src_id], mt_fr_dict[src_id]]\n",
    "    else:\n",
    "        fr_match[src_id] = [src_dict[src_id], ref_fr_dict[src_id], []]\n",
    "print(len(fr_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all sentence data from dictionaries\n",
    "\n",
    "#1. source sentences in English\n",
    "src_sent = [item[0] for item in de_match.values()]\n",
    "\n",
    "#2. reference German sentences\n",
    "ref_de_sent = [item[1] for item in de_match.values()]\n",
    "\n",
    "#3. reference french sentences\n",
    "ref_fr_sent = [item[1] for item in fr_match.values()]\n",
    "\n",
    "#4. translation score on German sentences\n",
    "mt_de = [item[2] for item in de_match.values()]\n",
    "        \n",
    "#5. translation score on French sentences\n",
    "mt_fr = [item[2] for item in fr_match.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert fr, de source order are the same\n",
    "assert list(fr_match.keys()) == list(de_match.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence preprocessing on source sentences\n",
    "# {img_id: [preprocessed tokens ... ]}\n",
    "\n",
    "def data_processing(src_sents, tokenizer, stop_words=None, MT=False):    \n",
    "    token_sents = []\n",
    "    \n",
    "    for i in range(len(src_sents)): \n",
    "        if MT: \n",
    "            sent = src_sents[i][0]\n",
    "        else:\n",
    "            sent = src_sents[i]\n",
    "            \n",
    "#         sent = sent.lower() \n",
    "        word_list = tokenizer.tokenize(sent) # Tokenizer\n",
    "#       word_list = [w for w in word_list if not w in stop_words] # stop words removal\n",
    "#         word_list = [w for w in word_list if w.isalnum()] # punct_filtered\n",
    "\n",
    "        #stemming\n",
    "        # stemmer = SnowballStemmer('english')\n",
    "        # sentence_stemmed = []\n",
    "        # for token in punct_filtered:\n",
    "        #     sentence_stemmed.append(stemmer.stem(token))\n",
    "        \n",
    "        if MT: \n",
    "            token_sents.append([word_list, src_sents[i][1]])\n",
    "        else:    \n",
    "            token_sents.append(word_list)\n",
    " \n",
    "    return token_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('english')\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "img_ids = list(src_dict.keys())\n",
    "\n",
    "src_tokens= {idx: val for idx, val in zip(img_ids, data_processing(src_sent, bert_tokenizer))}\n",
    "ref_de_tokens = {idx: val for idx, val in zip(img_ids, data_processing(ref_de_sent, bert_tokenizer))}\n",
    "ref_fr_tokens = {idx: val for idx, val in zip(img_ids, data_processing(ref_fr_sent, bert_tokenizer))}\n",
    "\n",
    "mt_fr_tokens = {idx:data_processing(fr_sent, bert_tokenizer, MT=True) for idx, fr_sent in zip(img_ids,mt_fr)}\n",
    "mt_de_tokens = {idx:data_processing(de_sent, bert_tokenizer, MT=True) for idx, de_sent in zip(img_ids, mt_de)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def oneByone_match(src_sent, ref_sent, mt_sent):\n",
    "#     source = []\n",
    "#     reference = []\n",
    "#     machineTranslation = []\n",
    "#     score = []\n",
    "\n",
    "#     for i in range(len(ref_sent)):\n",
    "#         src = src_sent[i]\n",
    "#         ref = ref_sent[i]        \n",
    "#         for mt in mt_sent[i]:\n",
    "#             if mt:\n",
    "#                 source.append(src)\n",
    "#                 reference.append(ref)\n",
    "#                 machineTranslation.append(mt[0])\n",
    "#                 score.append(mt[1])\n",
    "#     return (source, reference, machineTranslation, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(src_sent))\n",
    "# print(len(ref_de_sent))\n",
    "# print(len(mt_de))\n",
    "# de_sent = oneByone_match(src_sent, ref_de_sent, mt_de)\n",
    "# print(len(de_sent))\n",
    "# fr_sent = oneByone_match(src_sent, ref_fr_sent, mt_fr)\n",
    "# print(len(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id: 25622467670.jpg\n",
      "\n",
      "Original source sentence:\n",
      "privately owned poster and restaurant poster\n",
      "\n",
      "Tokenized source sentence:\n",
      "['privately', 'owned', 'poster', 'and', 'restaurant', 'poster']\n",
      "\n",
      "Original reference German sentence:\n",
      "schild für privatbesitz und schild eines restaurants\n",
      "\n",
      "Tokenized reference German sentence:\n",
      "['s', '##child', 'für', 'privat', '##besitz', 'und', 's', '##child', 'eines', 'restaurants']\n",
      "\n",
      "Original reference French sentence:\n",
      "une pancarte 'propriété privée 'et un panneau pour un restaurant\n",
      "\n",
      "Tokenized reference French sentence:\n",
      "['une', 'pan', '##car', '##te', \"'\", 'propriété', 'privée', \"'\", 'et', 'un', 'pan', '##neau', 'pour', 'un', 'restaurant']\n",
      "\n",
      "[['une affiche aveuse et un restaurant .', -1.60627323003466], ['une maison apprenant à une affiche de restaurant et une affiche de restaurant', -0.351114913586192], ['une affiche et des', -1.60795922940204]]\n",
      "[[['une', 'affiche', 'ave', '##use', 'et', 'un', 'restaurant', '.'], -1.60627323003466], [['une', 'maison', 'app', '##rena', '##nt', 'à', 'une', 'affiche', 'de', 'restaurant', 'et', 'une', 'affiche', 'de', 'restaurant'], -0.351114913586192], [['une', 'affiche', 'et', 'des'], -1.60795922940204]]\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "\n",
    "i = 30\n",
    "img_id = img_ids[i]\n",
    "print(f\"Image id: {img_id}\\n\")\n",
    "print(f\"Original source sentence:\\n{src_sent[i]}\\n\")\n",
    "print(f\"Tokenized source sentence:\\n{src_tokens[img_id]}\\n\")\n",
    "print(f\"Original reference German sentence:\\n{ref_de_sent[i]}\\n\")\n",
    "print(f\"Tokenized reference German sentence:\\n{ref_de_tokens[img_id]}\\n\")\n",
    "print(f\"Original reference French sentence:\\n{ref_fr_sent[i]}\\n\")\n",
    "print(f\"Tokenized reference French sentence:\\n{ref_fr_tokens[img_id]}\\n\")\n",
    "\n",
    "print(mt_fr[i])\n",
    "print(mt_fr_tokens[img_id])\n",
    "\n",
    "\n",
    "for i in range(len(src_sent)):\n",
    "    assert src_sent[i] == src_dict[img_ids[i]]\n",
    "    assert ref_fr_sent[i] == ref_fr_dict[img_ids[i]]\n",
    "    if len(mt_fr[i]) > 0:\n",
    "        assert mt_fr[i] == mt_fr_dict[img_ids[i]]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMD with Bert embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Using GPU: False\n"
     ]
    }
   ],
   "source": [
    "use_GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_GPU else \"cpu\")\n",
    "print('Device: ' + str(device))\n",
    "if use_GPU:\n",
    "    torch.cuda.manual_seed(0)\n",
    "    print('GPU: ' + str(torch.cuda.get_device_name(int(\"0\")))) \n",
    "print(\"Using GPU: {}\".format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenization(txt, tokenizer):\n",
    "    \n",
    "    tokens = tokenizer.tokenize(\"[CLS] \" + txt + \" [SEP]\")\n",
    "    \n",
    "    indexed_tokens= torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
    "    segments_ids = torch.tensor([0]*len(tokens)).unsqueeze(0)\n",
    "\n",
    "    return tokens[1:-1], indexed_tokens, segments_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Each Layers' output\n",
    "def layer_processing(model):\n",
    "    layers = []\n",
    "\n",
    "    def layer_hook(module, input_, output):\n",
    "        layers.append(output[0])\n",
    "\n",
    "    for i in model.encoder.layer:\n",
    "        i.register_forward_hook(layer_hook)\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased', return_dict=True)\n",
    "# bert_model.embeddings.word_embeddings\n",
    "bert_model.eval()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ein schlanker gelblicher hund beim absolvieren eines hindernislaufs , der in einem bereich mit nacktem erdboden aufgebaut ist\n",
      "['ein', 's', '##ch', '##lank', '##er', 'gel', '##bliche', '##r', 'hun', '##d', 'beim', 'ab', '##sol', '##vieren', 'eines', 'hin', '##dern', '##is', '##lauf', '##s', ',', 'der', 'in', 'einem', 'bere', '##ich', 'mit', 'na', '##ckte', '##m', 'er', '##d', '##boden', 'aufgebaut', 'ist']\n",
      "Num of tokens: 35\n",
      "Last State size: torch.Size([1, 35, 768])\n",
      "Pooling state size: torch.Size([1, 768])\n",
      "tensor([[[ 0.1663,  0.1419,  0.5582,  ...,  0.6827,  0.3857, -0.2903],\n",
      "         [-0.0510, -0.1802,  1.6126,  ...,  1.4017,  0.7537, -0.3717],\n",
      "         [ 0.3190, -0.2010,  0.5316,  ...,  0.8072,  0.5635, -0.2885],\n",
      "         ...,\n",
      "         [-0.0127, -0.5426,  0.6768,  ...,  0.7602,  0.9277, -0.4390],\n",
      "         [ 0.1554, -0.3840,  0.4842,  ...,  1.5283,  1.1576, -0.3436],\n",
      "         [-0.0743, -0.0172,  1.3659,  ...,  0.9191,  0.6367, -0.3853]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "torch.Size([1, 37, 768])\n",
      "tensor([[-0.1917, -0.4037,  0.4887,  ...,  0.9999,  0.8460, -0.4913],\n",
      "        [-0.1134, -0.8120,  1.1166,  ...,  1.4725,  1.4648, -0.0701],\n",
      "        [ 0.8585,  0.0128,  0.6682,  ...,  0.9493,  1.0975, -0.3609],\n",
      "        ...,\n",
      "        [-0.3934, -0.6844,  0.2225,  ...,  0.9895,  1.4139, -0.3576],\n",
      "        [-0.0025, -0.2187,  0.3589,  ...,  1.2094,  1.2425, -0.3323],\n",
      "        [-0.4622, -0.5473,  1.1580,  ...,  0.8084,  0.9063, -0.0444]],\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Test for Bert base multilingual cased\n",
    "# ref_tokens, ref_id, ref_seg = bert_tokenization(ref_de_sent[0], bert_tokenizer)\n",
    "# output = bert_model(ref_id)\n",
    "# print(ref_de_sent[0])\n",
    "# print(ref_tokens)\n",
    "# # print(bert_model.embeddings.word_embeddings(torch.tensor(bert_tokenizer(ref_de_sent[0])[\"input_ids\"])).size())\n",
    "# print(f\"Num of tokens: {len(ref_tokens)}\")\n",
    "# print(f\"Last State size: {output.last_hidden_state[:,1:-1,:].size()}\")\n",
    "# print(f\"Pooling state size: {output.pooler_output.size()}\")\n",
    "\n",
    "ref_tokens = bert_tokenizer.tokenize(ref_de_sent[0])\n",
    "ref_id = bert_tokenizer(ref_de_sent[0],return_tensors=\"pt\")\n",
    "output = bert_model(ref_id['input_ids'])\n",
    "\n",
    "print(ref_de_sent[0])\n",
    "print(ref_tokens)\n",
    "# print(bert_model.embeddings.word_embeddings(torch.tensor(bert_tokenizer(ref_de_sent[0])[\"input_ids\"])).size())\n",
    "print(f\"Num of tokens: {len(ref_tokens)}\")\n",
    "print(f\"Last State size: {output.last_hidden_state[:,1:-1,:].size()}\")\n",
    "print(f\"Pooling state size: {output.pooler_output.size()}\")\n",
    "print(output.last_hidden_state)\n",
    "\n",
    "### Each Layers' output\n",
    "# def processing(model):\n",
    "#     layers = []\n",
    "\n",
    "#     def layer_hook(module, input_, output):\n",
    "#         layers.append(output[0])\n",
    "\n",
    "#     for i in model.encoder.layer:\n",
    "#         i.register_forward_hook(layer_hook)\n",
    "\n",
    "#     return layers\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "layers = layer_processing(bert_model)\n",
    "bert_model(bert_tokenizer(ref_de_sent[0],return_tensors=\"pt\")['input_ids'])\n",
    "print(layers[0].size())\n",
    "out = torch.stack(layers[-4:]).squeeze(1).permute(1,0,2)\n",
    "result = torch.mean(out, dim=1)\n",
    "print(result)\n",
    "\n",
    "# layers2 = layer_processing(bert_model)\n",
    "# bert_model(bert_tokenizer(ref_de_sent[1],return_tensors=\"pt\")['input_ids'])\n",
    "# out = torch.stack(layers[-4:]).squeeze(1).permute(1,0,2)\n",
    "# result = torch.mean(out, dim=1)\n",
    "# print(result)\n",
    "# end = time.time()- start\n",
    "# print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Discard bert-base-multilingual-uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# bert_tokenizer_un = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "# bert_model_un = AutoModel.from_pretrained(\"bert-base-multilingual-uncased\",return_dict=True)\n",
    "# # bert_model_un.embeddings.word_embeddings\n",
    "# bert_model_un.eval()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test for Bert base multilingual uncased\n",
    "# ref_tokens, ref_id, ref_seg = bert_tokenization(ref_fr_sent[30], bert_tokenizer_un)\n",
    "# output = bert_model_un(ref_id)\n",
    "\n",
    "# print(ref_fr_sent[30])\n",
    "# print(ref_tokens)\n",
    "# print(f\"Num of tokens: {len(ref_tokens)}\")\n",
    "# print(f\"Last State size: {output.last_hidden_state[:,1:-1,:].size()}\")\n",
    "# print(f\"Pooling state size: {output.pooler_output.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlm_roberta_tokenization(txt, tokenizer):\n",
    "    \n",
    "    tokens = tokenizer.tokenize(\"<s> \" + txt + \" </s>\")\n",
    "    \n",
    "    indexed_tokens= torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
    "\n",
    "    return tokens[1:-1], indexed_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "xlm_r_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "xlm_r_model = AutoModel.from_pretrained(\"xlm-roberta-base\",return_dict=True)\n",
    "xlm_r_model.eval()\n",
    "# xlm_r_model.embeddings.word_embeddings\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une pancarte 'propriété privée 'et un panneau pour un restaurant\n",
      "['▁une', '▁pan', 'car', 'te', \"▁'\", 'prop', 'ri', 'été', '▁privée', \"▁'\", 'et', '▁un', '▁panne', 'au', '▁pour', '▁un', '▁restaurant']\n",
      "Num of tokens: 17\n",
      "Last State size: torch.Size([1, 17, 768])\n",
      "Pooling state size: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test for xlm-roberta-base\n",
    "\n",
    "# ref_tokens = xlm_r_tokenizer.tokenize(ref_de_sent[0])\n",
    "# ref_id = xlm_r_tokenizer(ref_de_sent[0], return_tensors=\"pt\")\n",
    "ref_tokens, ref_id = xlm_roberta_tokenization(ref_fr_sent[30], xlm_r_tokenizer)\n",
    "output = xlm_r_model(ref_id)\n",
    "\n",
    "print(ref_fr_sent[30])\n",
    "print(ref_tokens)\n",
    "print(f\"Num of tokens: {len(ref_tokens)}\")\n",
    "print(f\"Last State size: {output.last_hidden_state[:,1:-1,:].size()}\")\n",
    "print(f\"Pooling state size: {output.pooler_output.size()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "distil_bert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "distil_bert_model = AutoModel.from_pretrained(\"distilbert-base-multilingual-cased\", return_dict=True)\n",
    "distil_bert_model.eval()\n",
    "# distil_bert_model.embeddings.word_embeddings\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une pancarte 'propriété privée 'et un panneau pour un restaurant\n",
      "['une', 'pan', '##car', '##te', \"'\", 'propriété', 'privée', \"'\", 'et', 'un', 'pan', '##neau', 'pour', 'un', 'restaurant']\n",
      "Num of tokens: 15\n",
      "Last State size: torch.Size([1, 15, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test for distilBert\n",
    "ref_tokens = distil_bert_tokenizer.tokenize(ref_fr_sent[30])\n",
    "ref_id = distil_bert_tokenizer(ref_fr_sent[30], return_tensors=\"pt\")\n",
    "output = distil_bert_model(ref_id['input_ids'])\n",
    "\n",
    "print(ref_fr_sent[30])\n",
    "print(ref_tokens)\n",
    "print(f\"Num of tokens: {len(ref_tokens)}\")\n",
    "print(f\"Last State size: {output.last_hidden_state[:,1:-1,:].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RobertaTokenizer, RobertaModel\n",
    "# roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "# roberta_model.eval()\n",
    "# print()\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# xlm_mlm_tokenizer = AutoTokenizer.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# xlm_mlm_model = AutoModel.from_pretrained(\"xlm-mlm-100-1280\")\n",
    "# xlm_mlm_model.eval()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_tokens = roberta_tokenizer.tokenize(ref_de_sent[0])\n",
    "# ref_id = roberta_tokenizer(ref_de_sent[0], return_tensors=\"pt\")\n",
    "\n",
    "# output = distil_bert_model(ref_id['input_ids'])\n",
    "# print(ref_de_sent[0])\n",
    "# print(len(ref_tokens))\n",
    "# print(output.last_hidden_state.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteor Score & Fluent based penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Natural Language Toolkit: Machine Translation\n",
    "#\n",
    "# Copyright (C) 2001-2020 NLTK Project\n",
    "# Author: Uday Krishna <udaykrishna5@gmail.com>\n",
    "# URL: <http://nltk.org/>\n",
    "# For license information, see LICENSE.TXT\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain, product\n",
    "\n",
    "def _generate_enums(hypothesis, reference, preprocess=str.lower):\n",
    "    \"\"\"\n",
    "    Takes in string inputs for hypothesis and reference and returns\n",
    "    enumerated word lists for each of them\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :preprocess: preprocessing method (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :return: enumerated words list\n",
    "    :rtype: list of 2D tuples, list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list = list(enumerate(preprocess(hypothesis).split()))\n",
    "    reference_list = list(enumerate(preprocess(reference).split()))\n",
    "    return hypothesis_list, reference_list\n",
    "\n",
    "\n",
    "def exact_match(hypothesis, reference):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference\n",
    "    and returns a word mapping based on the enumerated\n",
    "    word id between hypothesis and reference\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list, reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _match_enums(hypothesis_list, reference_list)\n",
    "\n",
    "\n",
    "\n",
    "def _match_enums(enum_hypothesis_list, enum_reference_list):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference and returns\n",
    "    a word mapping between enum_hypothesis_list and enum_reference_list\n",
    "    based on the enumerated word id.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :type enum_hypothesis_list: list of tuples\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :type enum_reference_list: list of 2D tuples\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_hypothesis_list[i][1] == enum_reference_list[j][1]:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                (enum_hypothesis_list.pop(i)[1], enum_reference_list.pop(j)[1])\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def _enum_stem_match(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer()\n",
    "):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between enum_hypothesis_list and\n",
    "    enum_reference_list based on the enumerated word id. The function also\n",
    "    returns a enumerated list of unmatched words for hypothesis and reference.\n",
    "\n",
    "    :param enum_hypothesis_list:\n",
    "    :type enum_hypothesis_list:\n",
    "    :param enum_reference_list:\n",
    "    :type enum_reference_list:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    stemmed_enum_list1 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_hypothesis_list\n",
    "    ]\n",
    "\n",
    "    stemmed_enum_list2 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_reference_list\n",
    "    ]\n",
    "\n",
    "    word_match, enum_unmat_hypo_list, enum_unmat_ref_list = _match_enums(\n",
    "        stemmed_enum_list1, stemmed_enum_list2\n",
    "    )\n",
    "\n",
    "    enum_unmat_hypo_list = (\n",
    "        list(zip(*enum_unmat_hypo_list)) if len(enum_unmat_hypo_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_unmat_ref_list = (\n",
    "        list(zip(*enum_unmat_ref_list)) if len(enum_unmat_ref_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_hypothesis_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_hypo_list, enum_hypothesis_list)\n",
    "    )\n",
    "\n",
    "    enum_reference_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_ref_list, enum_reference_list)\n",
    "    )\n",
    "\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def stem_match(hypothesis, reference, stemmer=PorterStemmer()):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between hypothesis and reference\n",
    "\n",
    "    :param hypothesis:\n",
    "    :type hypothesis:\n",
    "    :param reference:\n",
    "    :type reference:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that\n",
    "                   implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_stem_match(enum_hypothesis_list, enum_reference_list, stemmer=stemmer)\n",
    "\n",
    "\n",
    "\n",
    "def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis\n",
    "    if any synonym of a hypothesis word is the exact match\n",
    "    to the reference word.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype:  list of tuples, list of tuples, list of tuples\n",
    "\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        hypothesis_syns = set(\n",
    "            chain(\n",
    "                *[\n",
    "                    [\n",
    "                        lemma.name()\n",
    "                        for lemma in synset.lemmas()\n",
    "                        if lemma.name().find(\"_\") < 0\n",
    "                    ]\n",
    "                    for synset in wordnet.synsets(enum_hypothesis_list[i][1])\n",
    "                ]\n",
    "            )\n",
    "        ).union({enum_hypothesis_list[i][1]})\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_reference_list[j][1] in hypothesis_syns:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                enum_hypothesis_list.pop(i), enum_reference_list.pop(j)\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def wordnetsyn_match(hypothesis, reference, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis if any synonym\n",
    "    of a hypothesis word is the exact match to the reference word.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of mapped tuples\n",
    "    :rtype: list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _enum_allign_words(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer(), wordnet=wordnet\n",
    "):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    in case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen. Takes enumerated list as input instead of\n",
    "    string input\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list,\n",
    "             unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    exact_matches, enum_hypothesis_list, enum_reference_list = _match_enums(\n",
    "        enum_hypothesis_list, enum_reference_list\n",
    "    )\n",
    "\n",
    "    stem_matches, enum_hypothesis_list, enum_reference_list = _enum_stem_match(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer\n",
    "    )\n",
    "\n",
    "    wns_matches, enum_hypothesis_list, enum_reference_list = _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        sorted(\n",
    "            exact_matches + stem_matches + wns_matches, key=lambda wordpair: wordpair[0]\n",
    "        ),\n",
    "        enum_hypothesis_list,\n",
    "        enum_reference_list,\n",
    "    )\n",
    "\n",
    "\n",
    "def allign_words(hypothesis, reference, stemmer=PorterStemmer(), wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    In case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_allign_words(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "def _count_chunks(matches):\n",
    "    \"\"\"\n",
    "    Counts the fewest possible number of chunks such that matched unigrams\n",
    "    of each chunk are adjacent to each other. This is used to caluclate the\n",
    "    fragmentation part of the metric.\n",
    "\n",
    "    :param matches: list containing a mapping of matched words (output of allign_words)\n",
    "    :return: Number of chunks a sentence is divided into post allignment\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    chunks = 1\n",
    "    while i < len(matches) - 1:\n",
    "        if (matches[i + 1][0] == matches[i][0] + 1) and (\n",
    "            matches[i + 1][1] == matches[i][1] + 1\n",
    "        ):\n",
    "            i += 1\n",
    "            continue\n",
    "        i += 1\n",
    "        chunks += 1\n",
    "    return chunks\n",
    "\n",
    "def penalty(    \n",
    "    reference,\n",
    "    hypothesis,\n",
    "    preprocess=str.lower,\n",
    "    stemmer=PorterStemmer(),\n",
    "    wordnet=wordnet):\n",
    "    \n",
    "    enum_hypothesis, enum_reference = _generate_enums(\n",
    "        hypothesis, reference, preprocess=preprocess\n",
    "    )\n",
    "    \n",
    "    translation_length = len(enum_hypothesis)\n",
    "    reference_length = len(enum_reference)\n",
    "    \n",
    "    matches, _, _ = _enum_allign_words(enum_hypothesis, enum_reference, stemmer=stemmer)\n",
    "    \n",
    "    matches_count = len(matches)\n",
    "    \n",
    "    try:\n",
    "        chunk_count = float(_count_chunks(matches))\n",
    "        frag_frac = chunk_count / matches_count\n",
    "        \n",
    "    except ZeroDivisionError: # No unigrams match\n",
    "        return 0\n",
    "    \n",
    "    return frag_frac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the aspects of model embedding.\n",
    "def tokens_to_fracdict(tokens):\n",
    "    cntdict = defaultdict(lambda : 0)\n",
    "        \n",
    "    for token in tokens:\n",
    "        cntdict[token] += 1\n",
    "    totalcnt = sum(cntdict.values())\n",
    "    return {token: float(cnt)/totalcnt for token, cnt in cntdict.items()}\n",
    "\n",
    "## From the aspects of model output, considering contextual relationship.\n",
    "## Each tokens means different, even they are the same.\n",
    "def tokens_to_fracdict_contextual(tokens):\n",
    "    \n",
    "    return {token: 1/len(tokens) for token in range(len(tokens))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are two components can be used as embedding\n",
    "## 1) model embedding \n",
    "## 2) Model output states\n",
    "\n",
    "def embedding_processing(sent1, sent2, tokenizer, model, embed_type):\n",
    "    \n",
    "    sent1_tokens = tokenizer.tokenize(sent1)\n",
    "    sent2_tokens = tokenizer.tokenize(sent2)\n",
    "    \n",
    "    if embed_type == 1:\n",
    "        \n",
    "        sent1_buckets = tokens_to_fracdict(sent1_tokens)\n",
    "        sent2_buckets = tokens_to_fracdict(sent2_tokens) \n",
    "        \n",
    "        sent1_embedding = model.embeddings.word_embeddings(torch.tensor(tokenizer.convert_tokens_to_ids(list(sent1_buckets.keys()))))\n",
    "        sent2_embedding = model.embeddings.word_embeddings(torch.tensor(tokenizer.convert_tokens_to_ids(list(sent2_buckets.keys()))))\n",
    "        \n",
    "    elif embed_type == 2:\n",
    "        \n",
    "#         sent1_buckets = tokens_to_fracdict(sent1_tokens)\n",
    "#         sent2_buckets = tokens_to_fracdict(sent2_tokens) \n",
    "        \n",
    "        sent1_buckets = tokens_to_fracdict_contextual(sent1_tokens)\n",
    "        sent2_buckets = tokens_to_fracdict_contextual(sent2_tokens) \n",
    "        \n",
    "        sent1_id = tokenizer(sent1,return_tensors=\"pt\")\n",
    "        sent2_id = tokenizer(sent2,return_tensors=\"pt\")\n",
    "        \n",
    "#         sent1_embedding = model(sent1_id['input_ids']).last_hidden_state.squeeze(0)\n",
    "#         sent2_embedding = model(sent2_id['input_ids']).last_hidden_state.squeeze(0)\n",
    "\n",
    "\n",
    "        layers = layer_processing(model)\n",
    "\n",
    "        model(sent1_id['input_ids'])\n",
    "        sent1_embedding = torch.mean(torch.stack(layers[-4:]).squeeze(1).permute(1,0,2), dim=1)\n",
    "        \n",
    "        model(sent2_id['input_ids'])\n",
    "        sent2_embedding = torch.mean(torch.stack(layers[-4:]).squeeze(1).permute(1,0,2), dim=1)\n",
    "        \n",
    "        del layers\n",
    "    \n",
    "    \n",
    "    if sent1_embedding.size()[0] - 2 == len(sent1_tokens):\n",
    "        sent1_embedding = sent1_embedding[1:-1,:] # Remove bos and eos tokens\n",
    "\n",
    "    if sent2_embedding.size()[0] - 2 == len(sent2_tokens):\n",
    "        sent2_embedding = sent2_embedding[1:-1,:] # Remove bos and eos tokens  \n",
    "    \n",
    "    \n",
    "    all_embedding = torch.cat([sent1_embedding, sent2_embedding])\n",
    "    \n",
    "#     print(len(sent1_tokens))\n",
    "#     print(len(sent2_tokens))\n",
    "#     print(sent1_embedding.size())\n",
    "#     print(sent2_embedding.size())\n",
    "\n",
    "    assert len(sent1_buckets) + len(sent2_buckets) == all_embedding.size()[0]\n",
    "    \n",
    "    return sent1_buckets, sent2_buckets, all_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_mover_distance_probspec(sent1_buckets, sent2_buckets, all_embedding, lpFile=None,):\n",
    "    \n",
    "#     first_sent_tokens  = bert_tokenizer.tokenize(first_sent)\n",
    "#     second_sent_tokens = bert_tokenizer.tokenize(second_sent)\n",
    "    \n",
    "#     first_sent_buckets = tokens_to_fracdict(first_sent_tokens)\n",
    "#     second_sent_buckets = tokens_to_fracdict(second_sent_tokens)\n",
    "    \n",
    "#     first_sent_embedding = model.embeddings.word_embeddings(torch.tensor(bert_tokenizer.convert_tokens_to_ids(list(first_sent_buckets.keys()))))\n",
    "#     second_sent_embedding = model.embeddings.word_embeddings(torch.tensor(bert_tokenizer.convert_tokens_to_ids(list(second_sent_buckets.keys()))))\n",
    "    \n",
    "#     all_embedding = torch.cat([first_sent_embedding, second_sent_embedding])\n",
    "    \n",
    "    \n",
    "#     first_sent_tokens, first_id, first_seg  = bert_tokenization(first_sent, bert_tokenizer)\n",
    "#     second_sent_tokens, second_id, second_seg = bert_tokenization(second_sent, bert_tokenizer)\n",
    "    \n",
    "#     first_sent_buckets = tokens_to_fracdict(first_sent_tokens)\n",
    "#     second_sent_buckets = tokens_to_fracdict(second_sent_tokens)\n",
    "    \n",
    "#     first_sent_embedding = bert_processing(first_id, first_seg, model)\n",
    "#     second_sent_embedding = bert_processing(second_id, second_seg, model)\n",
    "    \n",
    "#     all_embedding = torch.cat([first_sent_embedding, second_sent_embedding])\n",
    "    \n",
    "    \n",
    "    # Updated buckets with labeled name\n",
    "    first_sent_buckets = {f\"x{idx}\": item[1] for idx, item in enumerate(sent1_buckets.items())}\n",
    "    second_sent_buckets = {f\"y{idx}\": item[1] for idx, item in enumerate(sent2_buckets.items())}\n",
    "\n",
    "    var_names = list(first_sent_buckets.keys()) + list(second_sent_buckets.keys())\n",
    "    \n",
    "    assert len(var_names) == all_embedding.size(0)\n",
    "    \n",
    "    wordvecs = {token: embedding.detach().numpy() for token, embedding in zip(var_names, all_embedding)}\n",
    "    \n",
    "    \n",
    "    T = pulp.LpVariable.dicts('T_matrix', list(product(var_names, var_names)), lowBound=0)\n",
    "\n",
    "    prob = pulp.LpProblem('WMD', sense=pulp.LpMinimize)\n",
    "    \n",
    "    prob += pulp.lpSum([T[token1, token2]*euclidean(wordvecs[token1], wordvecs[token2])\n",
    "                        for token1, token2 in product(var_names, var_names)])\n",
    "    \n",
    "    for token2 in second_sent_buckets:   #constrains\n",
    "        prob += pulp.lpSum([T[token1, token2] for token1 in first_sent_buckets])==second_sent_buckets[token2]\n",
    "        \n",
    "    for token1 in first_sent_buckets:    #constrains\n",
    "        prob += pulp.lpSum([T[token1, token2] for token2 in second_sent_buckets])==first_sent_buckets[token1]\n",
    "\n",
    "    if lpFile!=None:\n",
    "        prob.writeLP(lpFile)\n",
    "\n",
    "    prob.solve()\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_mover_distance(sent1, sent2, tokenizer, model, embed_type, lpFile=None):\n",
    "    \n",
    "    sent1_buckets, sent2_buckets, embeddings = embedding_processing(sent1, sent2, tokenizer, model, embed_type)\n",
    "    \n",
    "    prob = word_mover_distance_probspec(sent1_buckets, sent2_buckets, embeddings, lpFile=lpFile)\n",
    "    \n",
    "    return pulp.value(prob.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluency_based_wmd(wmd, ref, hypo, gamma=0.2):\n",
    "    \n",
    "    frag_penalty = penalty(ref, hypo)\n",
    "\n",
    "    # print(frag_penalty)\n",
    "    \n",
    "    return wmd - gamma *(0.5 - frag_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_processing(src_sent[0],ref_de_sent[0], bert_tokenizer, bert_model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_WMD_WMDo(ref_sent, mt_sent, tokenizer, model, embed_type):\n",
    "    score = []\n",
    "    wmd = []\n",
    "    wmdo =[]\n",
    "\n",
    "    for i in range(len(ref_sent)):\n",
    "        ref = ref_sent[i]        \n",
    "        for mt in mt_sent[i]:\n",
    "            if mt:\n",
    "                hypo = mt[0]\n",
    "                wmd_tmp = word_mover_distance(ref, hypo, tokenizer, model, embed_type)\n",
    "                wmdo_tmp = fluency_based_wmd(wmd_tmp, ref, hypo)\n",
    "#                 wmdo_tmp = 0\n",
    "                score.append(mt[1])\n",
    "                wmd.append(wmd_tmp)\n",
    "                wmdo.append(wmdo_tmp)\n",
    "\n",
    "    return wmd, wmdo, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_WMD_WMDo_alt(sent, tokenizer, model, embed_type):\n",
    "#     wmd = []\n",
    "#     wmdo =[]\n",
    "    \n",
    "#     buckets1 = []\n",
    "#     buckets2 = []\n",
    "#     all_embeddings = []\n",
    "    \n",
    "#     for i in range(len(sent[0])):\n",
    "#         output = embedding_processing(sent[0][i], sent[2][i], tokenizer, model, embed_type) # src - mt\n",
    "# #         embedding_processing(sent[1][i], sent[2][i], tokenizer, model, embed_type) # ref-mt\n",
    "#         buckets1.append(output[0])\n",
    "#         buckets2.append(output[1])\n",
    "#         all_embeddings.append(output[2])\n",
    "        \n",
    "#     for k in range(len(buckets1)):\n",
    "#         prob = word_mover_distance_probspec(buckets1[k], buckets2[k], all_embeddings[k], lpFile=lpFile)\n",
    "#         wmd_tmp = pulp.value(prob.objective)\n",
    "#         wmdo_tmp = fluency_based_wmd(wmd_tmp, sent[0][k], sent[2][k])\n",
    "#         wmd.append(wmd_tmp)\n",
    "#         wmdo.append(wmdo_tmp)\n",
    "\n",
    "#     return wmd, wmdo, sent[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(wmd, wmdo, score):\n",
    "    pearson = stats.pearsonr(wmd, score)\n",
    "    pearson_o = stats.pearsonr(wmdo, score)\n",
    "    spearman = stats.spearmanr(wmd, score)\n",
    "    spearman_o = stats.spearmanr(wmdo, score)\n",
    "    print(\"Spearman Correlation:\", spearman, spearman_o)\n",
    "    print(\"Pearson Correlation:\", pearson, pearson_o)\n",
    "    return pearson, pearson_o, spearman, spearman_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(ref_de_sent, mt_de, bert_tokenizer, bert_model, embed_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German\n",
      "Average WMD: 11.92350722838354\n",
      "Average WMDo: 11.93565266229737\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.5264900763599432, pvalue=9.299201394871157e-248) SpearmanrResult(correlation=-0.527825014510426, pvalue=3.116225736984183e-249)\n",
      "Pearson Correlation: (-0.4988590021119278, 1.154527862257958e-218) (-0.5018554701795757, 1.0847530984382924e-221)\n"
     ]
    }
   ],
   "source": [
    "print(\"German\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd,wmdo,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German\n",
    "Average WMD: 0.8017151844060595\n",
    "Average WMDo: 0.8138606183198966\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.510027596930398, pvalue=4.212314562585338e-230) SpearmanrResult(correlation=-0.5219619561321359, pvalue=8.359442710590678e-243)\n",
    "Pearson Correlation: (-0.5097357138311421, 8.489667305524292e-230) (-0.5263318452409809, 1.3893750874154716e-247)\n",
    "    \n",
    "German\n",
    "Average WMD: 0.8451170232446427\n",
    "Average WMDo: 0.8572624571584787\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5167822958372177, pvalue=3.143442128396969e-237) SpearmanrResult(correlation=-0.527902437812766, pvalue=2.557939363753482e-249)\n",
    "Pearson Correlation: (-0.5175614221899548, 4.623107333941656e-238) (-0.5331211335090894, 3.7759802184007295e-255)\n",
    "\n",
    "German\n",
    "Average WMD: 11.92350722838354\n",
    "Average WMDo: 11.93565266229737\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5264900763599432, pvalue=9.299201394871157e-248) SpearmanrResult(correlation=-0.527825014510426, pvalue=3.116225736984183e-249)\n",
    "Pearson Correlation: (-0.4988590021119278, 1.154527862257958e-218) (-0.5018554701795757, 1.0847530984382924e-221)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(ref_fr_sent, mt_fr, bert_tokenizer, bert_model, embed_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\n",
      "Average WMD: 0.6042960387747216\n",
      "Average WMDo: 0.5843562557639091\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.5088781037811415, pvalue=4.238102393698617e-166) SpearmanrResult(correlation=-0.5095276962031406, pvalue=1.3749251885221357e-166)\n",
      "Pearson Correlation: (-0.4513739384178891, 9.4483659745375e-127) (-0.4753943913882638, 2.8100771767595054e-142)\n"
     ]
    }
   ],
   "source": [
    "print(\"French\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd, wmdo, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wmd, wmdo, score = compute_WMD_WMDo_alt(de_sent, bert_tokenizer, bert_model, embed_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(src_sent, mt_de, bert_tokenizer, bert_model, embed_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"German\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd, wmdo, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German\n",
    "Average WMD: 16.29980031455852\n",
    "Average WMDo: 16.320027543797018\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.29975434613344154, pvalue=2.927154570831462e-73) SpearmanrResult(correlation=-0.3013927051589536, pvalue=4.4202517417034795e-74)\n",
    "Pearson Correlation: (-0.3005912689344727, 1.116147711745209e-73) (-0.30129563647873175, 4.9458153364140074e-74)\n",
    "\n",
    "German\n",
    "Average WMD: 3.3968153183780254\n",
    "Average WMDo: 3.417042547616439\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.21422866982477823, pvalue=1.885174503990756e-37) SpearmanrResult(correlation=-0.2145094834367832, pvalue=1.5113773772990689e-37)\n",
    "Pearson Correlation: (-0.2268368401403627, 6.77521079069275e-42) (-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(src_sent, mt_fr, bert_tokenizer, bert_model, embed_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\n",
      "Average WMD: 15.939521637425933\n",
      "Average WMDo: 15.959814406385354\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.3107695748544288, pvalue=1.4922483868658528e-57) SpearmanrResult(correlation=-0.3100484209631477, pvalue=2.7908644823368746e-57)\n",
      "Pearson Correlation: (-0.2876862062916148, 3.1962490553298156e-49) (-0.2874546336258672, 3.840393624056795e-49)\n"
     ]
    }
   ],
   "source": [
    "print(\"French\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd, wmdo, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German\n",
    "Average WMD: 10.427111590705742\n",
    "Average WMDo: 0.0\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.29534751301923506, pvalue=4.450031532655668e-71) SpearmanrResult(correlation=nan, pvalue=nan)\n",
    "Pearson Correlation: (-0.27974182361659783, 1.1742674301265787e-63) (nan, nan)\n",
    "    \n",
    "German\n",
    "Average WMD: 17.18350542242003\n",
    "Average WMDo: 0.0\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.32986204801567076, pvalue=3.242058011986647e-89) SpearmanrResult(correlation=nan, pvalue=nan)\n",
    "Pearson Correlation: (-0.3227679331128431, 2.7421986260577897e-85) (nan, nan)\n",
    "\n",
    "German\n",
    "Average WMD: 17.18350542242003\n",
    "Average WMDo: 0.0\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.32986204801567076, pvalue=3.242058011986647e-89) SpearmanrResult(correlation=nan, pvalue=nan)\n",
    "Pearson Correlation: (-0.3227679331128431, 2.7421986260577897e-85) (nan, nan)\n",
    "    \n",
    "French\n",
    "Average WMD: 16.294238467579046\n",
    "Average WMDo: 0.0\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.3395921197358332, pvalue=4.690308677924282e-69) SpearmanrResult(correlation=nan, pvalue=nan)\n",
    "Pearson Correlation: (-0.30687943931248707, 4.2809690344793455e-56) (nan, nan)\n",
    "    \n",
    "German\n",
    "Average WMD: 18.81079347015398\n",
    "Average WMDo: 0.0\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.3707884378951234, pvalue=5.390859566935439e-114) SpearmanrResult(correlation=nan, pvalue=nan)\n",
    "Pearson Correlation: (-0.3479911991188516, 9.749048459798403e-100) (nan, nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yurunsong/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "norm_score = np.array(score)/np.sqrt(np.sum(np.array(score)**2))\n",
    "norm_wmd = np.array(wmd)/ np.sqrt(np.sum(np.array(wmd)**2))\n",
    "norm_wmdo = np.array(wmdo)/np.sqrt(np.sum(np.array(wmdo)**2))\n",
    "\n",
    "# wmd = np.array(wmd) - (sum(wmd)/len(wmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEHCAYAAAC5u6FsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5xcdX3/8dd7N5NkE2I2ibiFDZhUKEhISMwSbg0moIBVTIog4VIopaW1xQtaNPxEBKpyiZb+qFZLRUSkBOSSXxA0UGCrogSSJiEEiAbkshuqQLIxm+ySzebz++OcWc7OnjNzZndndybzeT4e89iZM99z5vvd2T2f872c71dmhnPOOZdWzXBnwDnnXGXxwOGcc64oHjicc84VxQOHc865onjgcM45VxQPHM4554oyopQHl3QK8H+BWuC7ZnZtzvujgB8As4E3gTPN7KXI+wcCzwJXmtnX0xwzzjvf+U6bMmXKYBRpSO3YsYOxY8cOdzaGXLWWG6q37NVabijvsq9evfoNM9s3d3vJAoekWuBbwAeBFuApScvN7NlIsguBrWZ2kKRFwHXAmZH3bwB+UuQx+5gyZQqrVq0ajGINqebmZubNmzfc2Rhy1VpuqN6yV2u5obzLLunluO2lbKqaA2wysxfNbBewFFiQk2YBcGv4/G7gREkCkLQQeBHYUOQxnXPOlVApA0cj8GrkdUu4LTaNme0GtgGTJI0FvgBc1Y9jOuecK6FS9nEoZlvu/CZJaa4CbjCz9rACUswxg4TSRcBFAA0NDTQ3NxfKb9lpb2+vyHwPVLWWG6q37NVabqjMspcycLQAB0ReTwY2J6RpkTQCGA9sAY4CTpd0PVAP7JHUCaxOcUwAzOwm4CaApqYmK9c2xHzKue2zlKq13FC9ZR+ucnd1ddHS0kJnZ+eQf3bW+PHjGT169LB9PsDo0aOZPHkymUwmVfpSBo6ngIMlTQVagUXA2TlplgPnA78CTgcetWDWxbnZBJKuBNrN7JthcCl0TOecS6WlpYVx48YxZcoUclo3hsz27dsZN27csHw2gJnx5ptv0tLSwtSpU1PtU7I+jrDP4mJgBfAccJeZbZB0taSPhsluJujT2AR8Fljcn2OWqgzOub1bZ2cnkyZNGragUQ4kMWnSpKJqXSW9j8PMHgQezNl2ReR5J3BGgWNcWeiYzjnXX9UcNLKK/R34nePOOeeK4oHDOef2MvPmzSvpTc8eOJxzzhXFA4dzzqW0bE0rx137KFMXP8Bx1z7KsjWtAz7mv/zLv3DjjTcCcMkll3DCCScA8Mgjj3Duueeyzz778IUvfIHZs2fzgQ98gCeffJJ58+bxx3/8xyxfvhyAjo4OFi1axIwZMzjzzDPp6OgYcL7y8cDhnHMpLFvTymX3rqe1rQMDWts6uOze9QMOHsceeyw///nPAVi1ahXt7e10dXXxi1/8grlz57Jjxw7mzZvH6tWrGTduHJdffjkPP/ww9913H1dcEYw1+va3v82YMWN4+umn+eIXv8jq1asHWty8PHA451wKS1ZspKOru9e2jq5ulqzYOKDjzpo1i9WrV7N9+3ZGjRrFMcccw6pVq/j5z3/O3LlzGTlyJKeccgoA06dP5/3vfz+ZTIbp06fz0ksvAfCzn/2Mc889F4AZM2YwY8aMAeWpkJIOx3XOub3F5rb45p+k7WllMhmmTJnCLbfcwrHHHsuMGTN47LHHeOGFF3jve99LJpPpGS5bU1PDqFGjep7v3r275zhDOazYaxzOOZfC/vV1RW0vxvHHH8/Xv/51jj/+eObOnct3vvMdZs6cmToYHH/88dx+++0APPPMMzz99NMDzlM+Hjiccy6FS08+hLpMba9tdZlaLj35kAEfe+7cubz22mscc8wxNDQ0MHr0aObOnVt4x9AnPvEJ2tvbmTFjBtdffz1z5swZcJ7y8aYq55xLYeGsYAWHJSs2srmtg/3r67j05EN6tg/EiSeeSFdXV8/rX//61z3P29vbe55feeWVvfbLvldXV8fSpUsHnI+0PHA451xKC2c1DkqgqHTeVOWcc64oHjicc84VxQOHc865onjgcM45V5SSBg5Jp0jaKGmTpD6LNEkaJenO8P2VkqaE2+dIWhs+1kn688g+L0laH75XuukfnXPOxSpZ4JBUC3wL+BBwGHCWpMNykl0IbDWzg4AbgOvC7c8ATWY2EzgF+Pdw2dis+WY208yaSpV/55yrVJU8rfocYJOZvWhmu4ClwIKcNAuAW8PndwMnSpKZ7QyXiQUYDVgJ8+mcc64IpQwcjcCrkdct4bbYNGGg2AZMApB0lKQNwHrg7yKBxICHJK2WdFEJ8++cc709fRfccDhcWR/8fPquAR+y1NOq33HHHUyfPp3DDz+cL3zhCwPOL5T2BsC4SVZyaw6JacxsJTBN0nuBWyX9JFyj/Dgz2yzpXcDDkp43s5/1+fAgqFwE0NDQQHNz8wCKMjza29srMt8DVa3lhuot+3CVe/z48Wzfvj1V2hHP3cfohz6Pdocn5W2vYss/RWdnJ7vf++f5d87j6KOP5t/+7d+44IILWLlyJW+99RZbtmzhkUce4cgjj+T2229nzpw5XH755Zx99tksXryYe++9l+eff56/+7u/Y/78+Xzzm98kk8nw+OOP88wzz/RMx/7rX/+az3/+8/zsZz+jvr6ehQsXcscdd/CRj3ykTz46OztTfwelDBwtwAGR15OBzQlpWsI+jPHAlmgCM3tO0g7gcGCVmW0Ot/9e0n0ETWJ9AoeZ3QTcBNDU1GTz5s0bjDINqebmZiox3wNVreWG6i37cJX7ueeeY9y4cekSP3497O49E652d1D3+PUw57x+52H27NmsW7cOgDFjxnDkkUeyceNGnnzySW688UZGjhzJaaedhiRmzZrFqFGjmDhxIkcffTSvvPIK48aNY+XKlXzqU59i3LhxHHPMMcyYMYOxY8fy3HPPMX/+fKZOnQrAeeedx1NPPcVZZ53VJx+jR49m1qxZqfJcyqaqp4CDJU2VNBJYBCzPSbMcOD98fjrwqJlZuM8IAEnvBg4BXpI0VtK4cPtY4CSCjnTnnCutbS3FbU8pd1r1uXPnDtq06mal6R4uWeAI+yQuBlYAzwF3mdkGSVdL+miY7GZgkqRNwGeB7JDdPwXWSVoL3Af8vZm9ATQAv5C0DngSeMDMflqqMjjnXI/xk4vbXoRSTat+1FFH8d///d+88cYbdHd3c8cdd/D+979/wPkt6SSHZvYg8GDOtisizzuBM2L2uw24LWb7i8ARg59T55wr4MQr4P5PQVekuSpTF2wfoLlz5/LVr36VY445hrFjx/ZrWvULLriAGTNmMHPmzJ5p1ffbbz+uueYa5s+fj5nxZ3/2ZyxYkDu4tXg+O65zzqUx4+PBz0euDpqnxk8OgkZ2+wCUclr1s88+m7PPPnvAeYzywOGcc2nN+PigBIpK53NVOeecK4oHDudcVSvVyKNKUuzvwAOHc65qjR49mjfffLOqg4eZ8eabbzJ69OjU+3gfh3Ouak2ePJmWlhZef/31YctDZ2dnUSftUhg9ejSTJ6cfVuyBwzlXtTKZTM9d1cOlubk59R3b5cKbqpxzzhXFA4dzzrmieOBwzjlXFA8czjnniuKBwznnXFE8cDjnnCuKBw7nnHNF8cDhnHOuKB44nHPOFaWkgUPSKZI2StokaXHM+6Mk3Rm+v1LSlHD7HElrw8c6SX+e9pjOOedKq2SBQ1It8C3gQ8BhwFmSDstJdiGw1cwOAm4Argu3PwM0mdlM4BTg3yWNSHlM55xzJVTKGsccYJOZvWhmu4ClQO6ahQuAW8PndwMnSpKZ7QzXLAcYDWSnrkxzTOeccyVUykkOG4FXI69bgKOS0pjZbknbgEnAG5KOAr4HvBv4i/D9NMcEQNJFwEUADQ0NNDc3D7hAQ629vb0i8z1Q1VpuqN6yV2u5oTLLXjBwSBoDfA440Mz+RtLBwCFm9uNCu8Zsy530PjGNma0Epkl6L3CrpJ+kPCbh/jcBNwE0NTXZvHnzCmS3/DQ3N1OJ+R6oai03VG/Zq7XcUJllT9NUdQvwFnBM+LoF+EqK/VqAAyKvJwObk9JIGgGMB7ZEE5jZc8AO4PCUx3TOOVdCaQLHe8zseqALwMw6iL/yz/UUcLCkqZJGAouA5TlplgPnh89PBx41Mwv3GQEg6d3AIcBLKY/pnHOuhNL0ceySVEfYJCTpPQQ1kLzCPomLgRVALfA9M9sg6WpglZktB24GbpO0iaCmsSjc/U+BxZK6gD3A35vZG+Hn9zlm+uI655wbqDSB48vAT4EDJN0OHAf8ZZqDm9mDwIM5266IPO8EzojZ7zbgtrTHdM45N3TyBg5JAp4HTgOOJmii+nT26t8551z1yRs4wv6GZWY2G3hgiPLknHOujKXpHH9C0pElz4lzzrmKkKaPYz7wt5JeJhgWK4LKyIyS5sw551xZShM4PlTyXDjnnKsYBZuqzOxloB44NXzUh9ucc85VoYKBQ9KngduBd4WPH0r6ZKkz5pxzrjylaaq6EDjKzHYASLoO+BXwr6XMmHPOufKUZlSVgO7I627STTninHNuL5SmxnELsFLSfeHrhQRThTjnnKtCBQOHmf2zpGaC+aMEXGBma0qdMeecc+UpzXocRwMbzOx/wtfjJB0VrpfhnHOuyqTp4/g20B55vSPc5pxzrgql6hw3s55V9sxsD6VdctY551wZSxM4XpT0KUmZ8PFp4MVSZ8w551x5ShM4/g44FmglWLr1KOCiNAeXdIqkjZI2SVoc8/4oSXeG76+UNCXc/kFJqyWtD3+eENmnOTzm2vDxrjR5cc45NzjSjKr6PW+vzJeapFrgW8AHCQLOU5KWm9mzkWQXAlvN7CBJi4DrgDOBN4BTzWyzpMMJVvxrjOx3jpmtKjZPrnosW9PKkhUb2dzWwf71dVx68iEsnNVYeEfnXEFpphy5XtI7wmaqRyS9IencFMeeA2wysxfNbBewFFiQk2YBcGv4/G7gREkyszVmtjncvgEYLWlUuiK5ardsTSuX3bue1rYODGht6+Cye9ezbE3rcGfNub1Cmk7uk8zs85L+nKDmcAbwGPDDAvs1Aq9GXmebuWLThGuUbwMmEdQ4sj4GrDGz6Drnt0jqBu4BvhLtvHeVJa5mUD+AfRfOamTJio10dHX3StvR1c2SFRu91rGX85rm0FChc66kDWY2TdJ/APeY2U8lrTOzIwrsdwZwspn9dfj6L4A5ZvbJSJoNYZqW8PULYZo3w9fTgOUEweuFcFujmbVKGkcQOH5oZj+I+fyLCPtiGhoaZi9dujTVL6SctLe3s88++wx3Nnpp6+jid9s62dW9h5G1NTSMH019Xabfx2rd2sGeyN9gjUTjPqL+HeMK7tuypQPj7X2FmDyxjle37Ezcb3rj+EEvx2Aqx+98KAxGuRP/nibUlcV3m6Scv/P58+evNrOm3O1pahz3S3oe6AD+XtK+QGeK/VqAAyKvJwObE9K0SBoBjAe2AEiaDNwHnJcNGgBm1hr+3C7pPwmaxPoEDjO7CbgJoKmpyebNm5ciy+WlubmZcsr3sjWtXPbIejq6asi2ctZlurnmtMP6dVV33LWP0tpW22f7F47oZuFH5+Xdd+ZVD9HW0XffusxuJo4dR2tbR5/3Guvr+OQ58wa9HIOp3L7zoTIY5U76e2qsr+XxxQM7dilV4neeZj2OxcAxQJOZdQE76dtXEecp4GBJUyWNJOhgX56TZjlwfvj8dODRcJ3zeoI1zi8zs8eziSWNkPTO8HkG+AjwTIq8uEGQrwmoGMvWtIb/5H1P7gC791jB/oi2jq7Y7R1de5gyqa7PLJx1mVouPfkQILkcV92/geOufZSpix/guGsf9T6RCrM54e8pabvrvzTDcTGzrWbWHT7fYWb/m2Kf3cDFBCOingPuMrMNkq6W9NEw2c3AJEmbgM8C2SG7FwMHAV/KGXY7Clgh6WlgLcEQ4f9IW1g3MIPxjxntuM7nqvs3FJW3qF++sIVoA6yAj81u7KlNJOV3684u71CvYPvX1xW13fVfqsDRX2b2oJn9iZm9x8y+Gm67wsyWh887zewMMzvIzOaY2Yvh9q+Y2Vgzmxl5/D4MWrPNbIaZTTOzT2cDmuu/bA2g0JX2YPxjxl3tx9m6syvvSXvCmOQ269xeOwN+vO61ntdp89uf2pQbPpeefAh1md5NVdGaphs8PnVIlcqOPmlt60C8fbLNXmkDPVfoSWmh9z9mmhEtxdROPnfXOi65c23ssb586jQ+c+fa1Mdq6wgC0cJZjVx68iFcdu/6VAEsKb976+idoSxX9LMWz9xDW/j99Fd2373xeyk3eQNH2GH9IeDQcNNzwE/DZihXobLNRdkTZ+4VenToar60tVJPE9Dly9Zz+xOv5A1AEFztF2qmyuoOR8e0tnVwyZ1rWfXyFr6ycHrPMVe9vKXXZwJ9AltUtkzRE0xcMIyqkbh82Xoee/71npPR/EP35Z7VrT2/k7j8DZZo0K6V6DajMeeE2J+Tfdw+QK/vOuk7HKxyRT9rV/eeQfms6PfrSidxOK6k/Qnu13gNWEPwPzkL+CNgfuQGvbLX1NRkq1ZV3o3mpRptka9jOkvAb6/9cMG0+U66EASXPWY9J6cfrXqFx1/YkvezPzd9N99YH39Nc+7RB/Y6OeeeAOcfui8/fOKVvMePnoB3vLU7saM9SaEy19dlkKBtZ1fRV73LfvIwS9bVsrmtg/F1GXbs2k1Xd99Pq8vUcs1pwe8ht/YUfS8uoOSetAEytWJ3t8WWq7G+jscXnxDzTv/l/l1lv/NSfFa5K+dRVZKKHo77NeDbZvYvOQf6FHANb4+GchXk8mWFO6bh7X6AQk1Lhe68jNYaLr17XexJEAqfjLNuf+IVmt49sedEHHeF+cDTr7F1Z3IwiOapPwrlMxqIsrWRz9y5tk9NIdeyNa20bu3oGVKaL6BF+1/iRohduXwDb+3e06v2cOnd67hy+YbY4yZ9L5CuebHYWo+PgKps+TrHj84NGgBmdiNwdOmy5Erl8mXrC16NZ80/dF9gcEek5Ds5pb3136BXh3Vcx/6XT53Wp5N0OOU23yV1+i9ZsbHXzWuFbG7rSDzRtnV09QkoXd1WdO0KCv8N9GeKFx8BVdny1Tjyhf7kW3Nd2bpj5auFE4Uee/51IBipUkwn9FBobevoaerI7di/5M61GMGoq86u7tQBaajkm/pkc1tH71tmC8ieZPtbc0pDEDsqKdr3Eqejq5vP3LmWJSs2xtY+4gYo5I6A2lsHIOwN8gWO8ZJOi9ku4B0lyo/rh7T/YN1FXs1C0BT0f+59mp1dewYtvwMl3j5Zxg29BfI2VQ231rYOpix+oE/TVRAItqc6RqZWPf0zaZv5+sPo21kd10eSJKmDPXcE1MjaGq45bXqvDv+h6qh3xcsXOP4bODXhvZ+VIC+uH4r5B6sR7El5hok2GRQbNATU1IjutB9WpHKrRfRXbv/H/EP3pWZne2L67Pc3YUyGbR1dPc1Opfx9NMY0HaW9Fyero6ubz921DugbPLKvm5ubmRd5zyeqLG+JfRxmdkG+x1Bm0iUrZhqQUSPS3e8ZbZ7oz53TBiULGkOhVrkTliTL1IpMTfr0uaLNbPesbmXCmEzi5+83vo6Xrv0wkP4CYCCSbp7rTwd2t1lRd+InfUZrWweXL1tf9Oe7wZVY45D02Xw7mtk/D352XLGKGZ3SmbLmEG2eqMY7p9M26WWbmuLuJ+mPjq5utnfuYY/FB/jWtg6mLn5gyGpc2QuN3KbQ8XWZfnWyF1NjyHe/T3aAx2DfM+PSy9dU9XWC+aB+ArwFfeaNc4Oov+tSJP2DRZuassdOe8KpDW96u2Plq0X1i2SVss29XAh67je4cvmGQSvvru491I8ZldhHM5S/17aOLi790TrQ2yPiWts6empZXTHVnkyNeqXPlbYj/9KTD8k7fPuOla964BhG+QLH+whmtP0wsBq4A3jEF00afEn9FNccW3hI6aUnH8KlP1rX6584U6NeTU1pOzKzus1SD9uNUw1/IEZwE9v8Q/ft19V3Pu2d5dOxHxccurqNCWMyjBk5IvaOdgimi4m76BD0TP0Sp9Boraz+XNC4wZMYOMxsLUGNY7GkY4GzgH+V9IXsJIVucCT1U/xuW3ACKThqKrcuGHmdryMz+w9fKbITG5bLiKnWto4BBdgkZTSALVHbzi7WXHFS3jTZodFRRjDzcVztupiLnGL6odzgS7Pm+L4EU41MJ1h46felzlS1Seqn2NW9p+DNVUtWbOxTne/qtp6+iXwdmWcddUDsbKLl6g8du/nwjP3I1PpJY7gVulFv4azGxJpn3PT1bR1dRY3WOuuoIm54cYMuMXBIukDST4EfEVzDftzMPmhmTwxZ7qpE0j/hyNqagqOmkqr02e35/sEfe/51rjltOo31wcJHjfV1fGx2+Q517DbjntWtnHnkAXmnVXeDJ1OjPoE6ex9NocWu4obyxuno6ua1PHfB5zruPRO9f2OY5atx3AzsR3BH0snAdyUtzz7SHFzSKZI2StokaXHM+6Mk3Rm+v1LSlHD7ByWtlrQ+/HlCZJ/Z4fZNkm6UKr/OmrSOQMP40QVHTSVV2bPb861FsLmtg4WzGnl88Qn89toP8/jiE3ruGC9XHV3dPPb866y54iReuvbDvHTth6tm1Eax5RyTqelXDTL7OY31dSw54wiWnH5ETxCIm4I/KXjE/V0n2b3HqE95MfA/r2zzBbaGWb7O8fkDObCkWuBbwAcJmriekrTczJ6NJLsQ2GpmB0laBFwHnAm8AZxqZpslHU6wimD2UvjbwEXAE8CDwCkEI78qVtI6AvXbfsP+9bWxtYoaiWVrWhP7KLLbF85q5Kr7N8T2C8TVRtJe9WVqxYga0TEMDfK5eSxmqvZKlZ3xNqnjOG6dlK+FM+SmmTImu3/SRIwLZzXGzpScOwV/7t9wNs/ZbflmIzYL8l2oucpvBBx++QLHBOCXZtbfPo05wKbsqn6SlhKsVR4NHAuAK8PndwPflCQzWxNJswEYLWkUMBF4h5n9KjzmD4CFVHjggPhZXpubf5O46FD2hqr6hDH10WaCL586reC8QFlpTsITxmT48qnTuOr+DQUDR5oTQbHTm+cGvGLn08qOCNrc1kFNGQ8QyE5JXz8mg1nQ2Ty+LkOmVr36teoytXxsdmOvNUOiJ/9Co5QKzdqbla/2mzgy8LTpvaZJX7amNfG7yn7/0VFaSfn2WXSHV76mqnOBNZJ+I+n7ki6SNK2IYzcC0Vn1Wni71tAnTbg41DZgUk6ajwFrzOytMH1LgWPuVRbOauSa06bHNkl1dHUj9e3Qzg0K2WNE+zKi8wJFXXryIQU7n8eMHMHCWY20FRjdlP2cQm3dm9s6kEh1B3ZcwFs4q7GoPo+2nV09zXPFzEY7lOoytXzj40dww5kz6ezaQ1tHF0Z4cg2nHYl+l19ZOL1Xk2P0u83XZJT9faa9KS9pe9oZDBbOaqS+Lv931W3Wk6+kvx2fRXd4JS7k1JMg6Hc4NnwcAxwIPGVmf1ZgvzOAk83sr8PXfwHMMbNPRtJsCNO0hK9fCNO8Gb6eBiwHTjKzFyQdCVxjZh8I358LfN7M+sypJekigiYtGhoaZi9durTAr6L8tLe3s88++wCwvnVbYroDJo7hd9s62dW9ByEMY2RtDQ3jRxf8J43T1tHFa20d7M4zr8X0xvFs/N/t7OqOr3HUSDROqOv5/HxpsyRRI3jnKON3eS4o48rW1tFF69aOVIFgZG0Nh/zRuFT5yv4+C+Ul+/sfqIY6+H2HmDwx+N0l5S9ahjTaOrpo2dIRW5a0x4r7HWe/51e3JE+YPb1xfMHjNNTR5zvP/m6TPrM/f9vlKPp/Xm7mz59f9EJOAJjZS5JGA3XhI/u8kBZ6TxI9GchdNTCbpiVcpnY8sAVA0mTgPuA8M3shkn5ygWNm830TcBMEKwCW6wpb+URXBvtiwkp8jfV1PH7OCbFj4Osy3Vxz2mH9bgtOWv2vsb6OT54zj7Y84+7r6zJc+dHDeiauy5c299iLDtieuAJgVlzZ0tw8lu0rKJSvIP/TEtv2IegXuOHMmb3ykLTmydiRtezc1R279GzUpTO6mXzY7J5jXrD4ASymYSBYoXFeYjnjJE1XEj1WoXuGkt4v9LeSK3ocI37VxyBfH9zrp1cv5xUAk+Sbq+r/ENQw9gU2EnRGfxO4yMzSDLZ+CjhY0lSgleAu9LNz0iwnWEnwV8DpwKNmZpLqgQeAy8zs8WxiM3tN0nZJRwMrgfOAf01V0gpXaP2CUswmWugz863d3dbR1WuW3twBAEnX8JvbOhg5pfBkjHFli35OmrW6o2XIHUAQzX/c70HAOUcf2Od3mx0mmp2upVbirKMO6DN8tOndE2Pz1zihO9Ua7f1pqil0rDQzLSet6Z1mfY2o6HGOu/ZR4qaTz+bL1xEvP/ku684D2oEfA78EVppZcntJDjPbLelighFRtcD3zGyDpKuBVeHd5zcDt0naRFDTWBTufjFwEPAlSV8Kt50UdtR/Avg+Qa3nJ+wFHeNpJI28ym4vxVKccZ85/9B9WbJiI5fcubYnD48vPqHgiJvs8bLPZ171UGxn+Pi6DA3jRV2mu2DtJF/Zkk422RUDc3+HS1Zs7DPyLJv/bOdumqveZWtaeez519mTEKgK5a+5ubnX62JPyPmU8uKj0N9noXy1Pre617b+ltENjXxTjhwqaSJB38Y8gqlH9gHWEYy2uqXQwc3sQYIhs9FtV0SedwJnxOz3FeArCcdcBRxe6LP3RvmuvNJcTfbnnzr3Kj46L1ZrWwefCdeTSJJ0ck+6++YPnV28umU3o0bUUSPYsSs5eBR71Z3virrQjZRprnrjjp9d53tbR1e/mlkGckJOMzx2MC8++lszWDirkWX/+yyN9bV7bXPU3iZvQ7KZbQF+HN5BPhs4Hvhb4K+AgoHDDZ24q8nsKnFTFj/QK232hAbpV1NbtqaVS+5aS9GDkBS0reeeDJJGZGX747Mr2yVJuiLNFyDzXVEnzdtVzJxIccePrvOdu3BT9Eq/J79H9A2U/TkhxwWx7NxRjZn/HJsAABsJSURBVPV1ffpmAOrHZGLv98lO6FjKk3l9XYbHF8/Lm2Zv7+uoJImjqiR9lKC2cRwwjeB+il9mH2ZW3rcYRzQ1NdmqVauGOxtFK7bTLPqPVT8mQ3vn7tjZTbNqBP/88Zm9bt7KbXOff+i+PPD0a4MysWBdppb3HTieJ17cmvfeibiO0lzZ+1dy85rb6ZztDF84q7FPAC3GhPBeimjNAXqf9Iu9CbFGQWCKfkefm76b771Qx5dPnVbUSTE6DX6txMgRhW/OrAEIVxVMuzqkBOccdeCgT/mx7CcPs2Rdco0jfvBHbeKw8kpSzp3jkmJHVeULHPcSBInHgdVmtqu0WSydSg4cbeMPLniVlXslNmVSHY+/sCXVZ2RP5r98YUvZTIeeJnAUoxSzANcApbhnPlv27PcS9z3W12WQglpbsd/3YDn36LeDR/Tvb3xO3uYfum+vGxOzr6NBVsBnc77z3KAw6+qHYi9eGuvret1gmFVJtZO9KnDsTSopcET/4C89opsbnhnR6y7h3KkhgLwL3lSiwQ4claRSyl6jYCnbwZrqJanchRYFC4bsfrhgbTs7Cq4cJ0esxMBR/n+hVSS3Ot69x/oEhOgEc5fevY7d3fluT3OuNPZY+tX8BqLQ3/b+9XVcvmx9r6V7k/ppbn/iFZrePXFIah6VVOPpDw8cZaSY9QggeXlO56rF7u7u1ItpGfDF+9YnTsg4WCf2NPfDVDoPHGXEJ25zrji/215c1+uOXd1MWfxAr4kiB/vEnjR67zM5I+oqOYjku3N8PXlqimY2oyQ5qmLVMD24c+Ugt7Y+mFO1F7oA3BtqIPlqHB8Jf/5D+PO28Oc5QPKMZq5flq1pZeeu3cOdDeeq1mBdtKW5AKz0NUUSJwUys5fN7GXgODP7vJmtDx+LCVYEdIMk2yY6GPdKOOf6bzBWFky78mElN00Xnk0Oxkr60+wLSccCY0uXpeqT1CmuqlkU1bny8Lm71g04eORbQyeqktcUSdM5fiHwPUnjCfo8thFMOeIGSdKVh2F9VtArNK7dOdd/3WZccudaVr28ZUD3fGSboKJzu0VV+iSOBWscZrbazI4AZgAzzWymmf1P6bNWPZKuPEbW1vRZue+cow9MVQ12zvVP9p6PwWi2ims0mDAmU/FTpRSscUhqAL4G7G9mH5J0GHCMmd1c8txViaTprhvGj4yd4K7p3RP53F3rynatbOcqnUHqzuuke0KWrNgYe69VdunlSpamj+P7BGtq7B++/jXwmVJlqBolrQmetDTmwlmNfOPjR3jNw7kSStN5nR3Y0houTpYdartsTWvi/q1tHYNTmxlGafo43mlmd0m6DHoWaEp1e7OkU4D/S7CQ03fN7Nqc90cBPyCYsv1N4MxwqdpJwN3AkcD3zeziyD7NwH5A9lvJLvBU0eJqFs3Nv8mbHihqqnPvH3EuvTSd1/mm6s83LLfS7+NIU+PYEZ7IDSBctrXgSoCSaoFvAR8CDgPOCpu5oi4EtprZQcANwHXh9k7gS8A/Jhz+nLCvZebeEDT6a+GsRm74+EwytYVHX9XXZbjhzJm8dO2HhyBnzlU2QarO63yLX+UblpsNLpUqTY3jcwRrg79H0uMEa5D3WbUvxhxgk5m9CCBpKbAAeDaSZgFwZfj8buCbkmRmO4BfSDooVSmqWPaK5Yv3rY9dLW9MpoavnTaj15VN2rUXnKtGSevJx8m38mZ2/6QVMvfq+zjMbDXwfoJFnf4WmGZm61IcuxF4NfK6JdwWm8bMdhPUZCalOPYtktZK+pJUxBJte6mFsxqpHzMy9r0JY0f1+Qc4+6gD8x6vvi6Tqhbj3N4k2794w5kzUw/FjatVRIfaLpzVSGNCk1cl38dRcD0OSS8AS8zsO5FtPzazj+TZDUlnACeb2V+Hr/8CmGNmn4yk2RCmaYl81hwzezN8/ZdAU04fR6OZtUoaB9wD/NDMfhDz+RcBFwE0NDTMXrp0ad5ylqP29nb22WefVGnXtya3Hk5vHN/zvK2ji99t62RXd/wyRDUSjROCP+iWLR0Mx6TtDXXwu8q9GBuQai37cJd7ZG0Nh/zRuH7tG/2fGllbQ8P40b0GtrR1dNG6tYM9kXNt9v+svi5T1P/5UJs/f36/1+PoAuZLOgr423AlwDQ9Oi3AAZHXk4HNCWlaJI0AxgN5lzIzs9bw53ZJ/0nQJNYncJjZTcBNECzkVK4LpeRTzAIvX7z20dgqc2N9HZ88JzjGsjWtXPbIejq6ashWNjM1Yp/RI3pWbIvO2jl18QNFhY3cmxX7q1IWMyqFai37cJY7UyuWnH4E80rYUZ1vGvdyXsgpSZpvaqeZnSnp88DPJX2cdINzngIOljQVaAUWAWfnpFkOnA/8CjgdeNTyVIHC4FJvZm9IyhBMxPhfKfKy10u6FyTawRc3AqRrjzFm5AjWXHFSn2PWj8mknj8rO1V09p8Dih/BlR31VVsjJozJ0Lazq6g8OFesCWMyRa/v3h9xoyYrWZrAIQAzu17SaoJ7OiYW2ikctntxmL4W+J6ZbZB0NbDKzJYDNwO3SdpEUNNY1POh0kvAO4CRkhYCJwEvAyvCoFFLEDT+I21h92bZP8p8i9PkGwESJ+0w32yAiv5zJK0RnST6D9zc3Myas+b1vDdl8QOpj+NcnHw1a1e8NIHjiuwTM3tE0skEtYSCzOxB4MGcbdHjdZIwQsvMpiQcdnaaz65Gha5q8o0AibOtI/nE31hfl3f1tLaEoCHghjNnFrX6WuMgrFMyWM1opVbjYz0GnYAz5xxQluuNV6p8CzkdambPA62S3pfz9o9Lmy1XCmmas6KSAk1jfR2PLz4h72cVGqZYzNVeXL6z0tzUGG1Gi+apVuKsow6g6d0TueTOtYMyDGDCmAxmQYdofzROqGPCGKuI5rnG+jrmH7ovjz3/elkvQGbAPatbh2y98WqQr8bxOeBvgG/EvGdA/jOHKztpmrOiig00g7VvUr7j5ucy8gePTK36NKMlyc2vgLpMDTu74keg9XxGjVhyxhG9jp+77nQajfV11NfV8OVTD+bSu9cNyZryx71nIr98YUvRQTP34uHyZetTr/092LK13/o8QbvSF04qN4mBw8z+Jvw5f+iy40qtmKv9YgPNYO2bdLxLEm6kMt5uzooGkWI6PhfOamTVy1u4/YlXevY3gsEDmRrFTo2d7zOi5c/NV5yeoLrtN332rZUKTmiZvWmt2JP3S2929Gk6zNYisifj9s7dvcofdwHwlYXThyVwxNV+k0YDVvINd+UmX1PVafl2NLN7Bz87rtwMZDRI2n37DFU8Iv4qfSBNZ2k89vzrfU44Xd3GhDEZxowcERsAOvPURqLlzy1j9OQcDarZ+cnifnfL1rRy5fINPVfUUjCAoTGyf7HNRpvbOgp+T/mGkkYl9UUlBb66TA27dlvPe2NS1O6iahQ/LUixfXmuePmaqk7N854BHjjcgOU26bS2ddC6tZtla1r7nJwGs/krTtIVadvOLtZccRLHxdwrk7YJZDCGY6Y5Rr7+oDhpTqZp8570/XxsdiP3rG7tsz26JkVzczPPnjOPmVc9lLp/aHxdJjZfpf47cfmbqi4Yyoy46hR3b8kes9iT8WA3f+UqdKVa7HDm4ZD7O6rJ08w12CfTfN9P07snFvzelq1pLWpQQdLIvVL/nbh0w3GR9GFgGjA6u83Mri5Vplz1KPZkXMobqQpdqVZKE0huE1lcDaS+LsNHjtiPJSs2csmdawft5Jr0/aT53oqdLTbf731vu+Gu3KRZAfA7wBhgPvBdgju8nyxxvlyVKKeTcaEr1UpsAkkqE9CniXCo14iI9p0snrmH1rY0qzwEMjUq69/73i5NjeNYM5sh6Wkzu0rSN/D+DTdI4k7GNRq8k0Lajt2suA7t6BX5NadNr7gmkLir7+OufTRxAaKhKE9uTWhX9x5ETexoqDGZGkZlanvubamvy3DlR0s/TYhLliZwZC8Hd0ran2Clvqmly5KrJnFXxI0TugflpBDX8Z72qjpp32tOmz4oI7iG23D318T1bcXdk1OXqeVrkU50Vx7SBI4fS6oHlgD/Q/C9frekuXJVJfeKuLm5eVCOm29ZzzTt7cN5RV5qw91EmDg/GoWns3HDr2DgMLN/Cp/eI+nHwGgzK7h0rHPDbSBX1cN9RV5qw91fU+p7clxpFeyNklQr6aOSPgX8A3ChpM+WPmvODUzS1XOaq+qB7FsJFs5q5JrTptNYX9ez8t01Q9gkVGjlPFfe0jRV3Q90AuuB9Ld1OjfMymWurXI1nENWc/u2RtbWDGngcgOTJnBMNrMZJc+Jc4OsnObacn1FA1dzc3NJV+BzgytN4PiJpJPM7KGS58a5QTYUc205V23S3HHzBHCfpA5Jf5C0XdIf0hxc0imSNkraJGlxzPujJN0Zvr9S0pRw+yRJj0lql/TNnH1mS1of7nOj5CvfOOfcUEoTOL4BHAOMMbN3mNk4M3tHoZ0k1QLfAj4EHAacJemwnGQXAlvN7CDgBuC6cHsn8CXgH2MO/W3gIuDg8HFKijI455wbJGkCx2+AZ8zSrkDdYw6wycxeNLNdwFJgQU6aBcCt4fO7gRMlycx2mNkvCAJID0n7Ae8ws1+F+fkBsLDIfDnnnBuANH0crwHNkn4CvJXdaGb/XGC/RuDVyOsW4KikNGa2W9I2YBLwRp5jtuQcM7YRWtJFBDUTGhoaBu2msqHU3t5ekfkeqGotN1Rv2au13FCZZU8TOH4bPkaGj7Ti+h5yay1p0vQrvZndBNwE0NTUZPPmzctz2PLU3NxMJeZ7oKq13FC9Za/WckNllj1v4Aj7KfYxs0v7cewW4IDI68nA5oQ0LZJGAOOBLQWOObnAMZ1zzpVQ3j4OM+sG3tfPYz8FHCxpqqSRwCJgeU6a5cD54fPTgUfz9aWY2WvAdklHh6OpzgP+Xz/z55xzrh/SNFWtlbQc+BGwI7ux0JrjYZ/FxcAKoBb4npltkHQ1sMrMlgM3A7dJ2kRQ01iU3V/SS8A7gJGSFgInmdmzwCeA7wN1wE/Ch3POuSGSJnBMJJhKPTrzWKo1x83sQeDBnG1XRJ53Amck7DslYfsq4PBCn+2cc6400syO62uPO+ec65FmdtzJku6T9HtJv5N0j6TJhfZzzjm3d0pzA+AtBJ3Y+xPcM3F/uM0551wVShM49jWzW8xsd/j4PrBvifPlnHOuTKUJHG9IOjdc0KlW0rkEneXOOeeqUJrA8VfAx4H/JZh+5PRwm3POuSqUZlTVK8BHhyAvzjnnKkBi4JB0RdJ7gJnZP5UgP84558pcvhrHjphtYwnW0JgEeOBwzrkqlBg4zOwb2eeSxgGfBi4gWFfjG0n7Oeec27sVmh13IvBZ4ByCBZfeZ2ZbhyJjzjnnylO+Po4lwGkEa1pMN7P2IcuVc865spVvOO7nCO4WvxzYLOkP4WO7pD8MTfacc86Vm3x9HGnu8XDOOVdlPDg455wrSkkDh6RTJG2UtEnS4pj3R0m6M3x/paQpkfcuC7dvlHRyZPtLktZLWitpVSnz75xzrq80Czn1S7he+beADxKsFf6UpOXhKn5ZFwJbzewgSYuA64AzJR1GsBrgNIJ+lv+S9CfhUrYA883sjVLl3TnnXLJS1jjmAJvM7EUz20Vw/8eCnDQLCIb5AtwNnBiuJb4AWGpmb5nZb4FN4fGcc84Ns1IGjkbg1cjrlnBbbBoz2w1sI7grPd++BjwkabWki0qQb+ecc3mUrKkKUMw2S5km377HmdlmSe8CHpb0vJn9rM+HB0HlIoCGhgaam5tTZ7xctLe3V2S+B6payw3VW/ZqLTdUZtlLGThagAMirycDmxPStEgaAYwHtuTb18yyP38v6T6CJqw+gcPMbiK4eZGmpiabN2/ewEs0xJqbm6nEfA9UtZYbqrfs1VpuqMyyl7Kp6ingYElTJY0k6OxenpNmOXB++Px04FEzs3D7onDU1VTgYOBJSWPDebOQNBY4CXimhGVwzjmXo2Q1DjPbLeliYAVQC3zPzDZIuhpYZWbLgZuB2yRtIqhpLAr33SDpLuBZYDfwD2bWLakBuC/oP2cE8J9m9tNSlcE551xfpWyqwsweBB7M2XZF5HkncEbCvl8Fvpqz7UXgiMHPqXPOubT8znHnnHNF8cDhnHOuKB44nHPOFcUDh3POuaJ44HDOOVcUDxzOOeeK4oHDOedcUTxwOOecK4oHDuecc0XxwOGcc64oHjicc84VxQOHc865onjgcM45VxQPHM4554rigcM551xRSho4JJ0iaaOkTZIWx7w/StKd4fsrJU2JvHdZuH2jpJPTHtM551xplSxwSKoFvgV8CDgMOEvSYTnJLgS2mtlBwA3AdeG+hxGsBjgNOAX4N0m1KY/pnHOuhEpZ45gDbDKzF81sF7AUWJCTZgFwa/j8buBEBevCLgCWmtlbZvZbYFN4vDTHdM45V0KlDByNwKuR1y3httg0ZrYb2AZMyrNvmmM655wroVKuOa6YbZYyTdL2uECXe8zgwNJFwEUADQ0NNDc3J2a0XLW3t1dkvgeqWssN1Vv2ai03VGbZSxk4WoADIq8nA5sT0rRIGgGMB7YU2LfQMQEws5uAmwCampps3rx5/SrEcGpubqYS8z1Q1VpuqN6yV2u5oTLLXsqmqqeAgyVNlTSSoLN7eU6a5cD54fPTgUfNzMLti8JRV1OBg4EnUx7TOedcCZWsxmFmuyVdDKwAaoHvmdkGSVcDq8xsOXAzcJukTQQ1jUXhvhsk3QU8C+wG/sHMugHijlmqMjjnnOurlE1VmNmDwIM5266IPO8EzkjY96vAV9Mc0znn3NDxO8edc84VxQOHc865onjgcM45VxQPHM4554rigcM551xRPHA455wrigcO55xzRfHA4ZxzrigeOJxzzhXFA4dzzrmieOBwzjlXFA8czjnniuKBwznnXFE8cDjnnCuKBw7nnHNFUbDg3t5N0uvAy8Odj354J/DGcGdiGFRruaF6y16t5YbyLvu7zWzf3I1VETgqlaRVZtY03PkYatVabqjesldruaEyy+5NVc4554rigcM551xRPHCUt5uGOwPDpFrLDdVb9motN1Rg2b2PwznnXFG8xuGcc64oHjiGmaSJkh6W9Jvw54SEdOeHaX4j6fyY95dLeqb0OR4cAym3pDGSHpD0vKQNkq4d2twXT9IpkjZK2iRpccz7oyTdGb6/UtKUyHuXhds3Sjp5KPM9GPpbdkkflLRa0vrw5wlDnfeBGMh3Hr5/oKR2Sf84VHlOzcz8MYwP4Hpgcfh8MXBdTJqJwIvhzwnh8wmR908D/hN4ZrjLMxTlBsYA88M0I4GfAx8a7jLlKWst8ALwx2F+1wGH5aT5e+A74fNFwJ3h88PC9KOAqeFxaoe7TENU9lnA/uHzw4HW4S7PUJQ78v49wI+Afxzu8uQ+vMYx/BYAt4bPbwUWxqQ5GXjYzLaY2VbgYeAUAEn7AJ8FvjIEeR1M/S63me00s8cAzGwX8D/A5CHIc3/NATaZ2YthfpcSlD8q+vu4GzhRksLtS83sLTP7LbApPF6l6HfZzWyNmW0Ot28ARksaNSS5HriBfOdIWkhwobRhiPJbFA8cw6/BzF4DCH++KyZNI/Bq5HVLuA3gn4BvADtLmckSGGi5AZBUD5wKPFKifA6GguWIpjGz3cA2YFLKfcvZQMoe9TFgjZm9VaJ8DrZ+l1vSWOALwFVDkM9+GTHcGagGkv4L+KOYt76Y9hAx20zSTOAgM7skt320HJSq3JHjjwDuAG40sxeLz+GQyVuOAmnS7FvOBlL24E1pGnAdcNIg5qvUBlLuq4AbzKw9rICUHQ8cQ8DMPpD0nqTfSdrPzF6TtB/w+5hkLcC8yOvJQDNwDDBb0ksE3+W7JDWb2TzKQAnLnXUT8Bsz+5dByG4ptQAHRF5PBjYnpGkJA+J4YEvKfcvZQMqOpMnAfcB5ZvZC6bM7aAZS7qOA0yVdD9QDeyR1mtk3S5/tlIa7k6XaH8ASencSXx+TZiLwW4KO4Qnh84k5aaZQWZ3jAyo3QZ/OPUDNcJclRVlHELRXT+XtjtJpOWn+gd4dpXeFz6fRu3P8RSqrc3wgZa8P039suMsxlOXOSXMlZdg5PuwZqPYHQVvuI8Bvwp/ZE2MT8N1Iur8i6BjdBFwQc5xKCxz9LjfB1ZsBzwFrw8dfD3eZCpT3z4BfE4y0+WK47Wrgo+Hz0QQjaDYBTwJ/HNn3i+F+Gynj0WODXXbgcmBH5DteC7xruMszFN955BhlGTj8znHnnHNF8VFVzjnniuKBwznnXFE8cDjnnCuKBw7nnHNF8cDhnHOuKB44XFWTNKWSZhV2rhx44HCuCoR3Jjs3KDxwOAe1kv4jXNvjIUl1AJKaJTWFz98ZTu2CpL+UtEzS/ZJ+K+liSZ+VtEbSE5Imhun+RtJTktZJukfSmHD79yXdKOmXkl6UdHpuhiSNDdccWSfpGUlnhtuPDPdbJ+lJSeMkjZZ0S7huxRpJ8yP5/JGk+4GHwm2Xhnl6WlLZTqLnypsHDufgYOBbZjYNaCOYibWQw4GzCabP/iqw08xmAb8CzgvT3GtmR5rZEQR3uV8Y2X8/4E+BjwBxC1GdAmw2syPM7HDgp5JGAncCnw6P+QGgg2DqCsxsOnAWcKuk0eFxjgHON7MTJJ0UlnUOMJNgnrPjU5TVuV48cDgHvzWzteHz1QTTtxTymJltN7PXCabDvj/cvj6y/+GSfi5pPXAOwbxTWcvMbI+ZPQs0xBx/PfABSddJmmtm24BDgNfM7CkAM/uDBdNx/ylwW7jteeBl4E/C4zxsZlvC5yeFjzUEa5gcShBInCuKt3s6B9E1HrqBuvD5bt6+uBpNb9F99kRe7+Ht/6vvAwvNbJ2kv6T3TL/R/fvMnW1mv5Y0m2C+o2skPQQsI35K9Xxzb+/ISXeNmf17nvTOFeQ1DueSvQTMDp/36YdIYRzwmqQMQY0jNUn7EzR//RD4OvA+4Hlgf0lHhmnGhZ3eP8seX9KfAAcSTIiYawXwV+GqkUhqlBS3gJZzeXmNw7lkXwfukvQXwKP92P9LwEqCpqP1BIEkrenAEkl7gC7gE2a2K+wk/9ewA7+DoJ/j34DvhE1iu4G/NLO3chcBMrOHJL0X+FX4XjtwLvFroTiXyGfHdc45VxRvqnLOOVcUDxzOOeeK4oHDOedcUTxwOOecK4oHDuecc0XxwOGcc64oHjicc84VxQOHc865ovx/BXaQPpMH3/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.scatter(np.array(score)[:200],wmd[:200])\n",
    "plt.scatter(norm_score,norm_wmd)\n",
    "plt.scatter(norm_score,norm_wmdo)\n",
    "# plt.xlim([-3,3])\n",
    "# plt.ylim([-1.5,1.5])\n",
    "plt.xlabel(\"human score\")\n",
    "plt.ylabel(\"Normalized WMD score\")\n",
    "plt.legend([\"wmd\", \"wmdo\"])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bert_processing(indexed_tokens,segments_ids, model):\n",
    "\n",
    "# #     sentences_embedding = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "# #         for i in range(len(indexed_tokens)):\n",
    "\n",
    "#         # \"encoded_layers\" has shape [12 x 1 x N x 768]\n",
    "\n",
    "#         encoded_layers, _ = model(indexed_tokens, segments_ids)\n",
    "\n",
    "#         token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "#         token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "#         token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "#         # \"token_embeddings\" has shape [N x 12 x 768]\n",
    "\n",
    "#         token_vecs_sum = []\n",
    "\n",
    "#         for token in token_embeddings:\n",
    "            \n",
    "# #             sum_vec = torch.tensor(gen_mean(token, 4))\n",
    "#             sum_vec = torch.mean(token[-4:], dim=0)\n",
    "\n",
    "#             token_vecs_sum.append(sum_vec)\n",
    "\n",
    "#         # \"token_vecs\" is a tensor with shape [N x 768]\n",
    "        \n",
    "#         token_vecs = torch.stack(token_vecs_sum, dim=0)\n",
    "\n",
    "#     return token_vecs[1:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_mean(vals, p):\n",
    "#     p = float(p)\n",
    "#     return np.power(np.mean(np.power(np.array(vals, dtype=np.float32),p),axis=0),1 / p)  \n",
    "\n",
    "\n",
    "# def get_sentence_embedding(sentence, embeddings, chosen_operations):\n",
    "#     word_embeddings = []\n",
    "#     for tok in sentence:\n",
    "#         vec = embeddings.vectors.get(tok)\n",
    "#         if vec is not None:\n",
    "#             word_embeddings.append(vec)\n",
    "\n",
    "#     if not word_embeddings:\n",
    "#         print('No word embeddings for sentence:\\n{}'.format(sentence))\n",
    "#         size = 0\n",
    "#         for o in chosen_operations:\n",
    "#             size += operations[o][1](embeddings.embeddings_dimensionality)\n",
    "#         sentence_embedding = np.zeros(size)\n",
    "#     else:\n",
    "#         concat_embs = []\n",
    "#         for o in chosen_operations:\n",
    "#             concat_embs += operations[o][0](word_embeddings)\n",
    "#         sentence_embedding = np.concatenate(\n",
    "#             concat_embs,\n",
    "#             axis=0\n",
    "#         )\n",
    "\n",
    "#     return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "# s2 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "\n",
    "# sent1_buckets, sent2_buckets, embeddings = embedding_processing(s1, s2, bert_tokenizer, bert_model, 2)\n",
    "\n",
    "# print(len(sent1_buckets))\n",
    "# print(len(sent2_buckets))\n",
    "# print(embeddings.size())\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
