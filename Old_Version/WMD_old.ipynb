{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "# nltk.download('punkt') # Download the tokenizer model\n",
    "# nltk.download('wordnet') # Download the wordnet corpora\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk import meteor_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.translate import meteor_score\n",
    "from nltk.translate import bleu_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from itertools import product\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pulp\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all json data\n",
    "data_path = sys.path[0]+\"/human_assessment/\"\n",
    "\n",
    "with open(data_path+'MMTsourcedict.json') as json_file:\n",
    "    src_dict = json.load(json_file)\n",
    "with open(data_path+'MMTgolddict_de.json') as json_file:\n",
    "    ref_de_dict = json.load(json_file)\n",
    "with open(data_path+'MMTtranslationdict_de.json') as json_file:\n",
    "    mt_de_dict = json.load(json_file)\n",
    "with open(data_path+'MMTgolddict_fr.json') as json_file:\n",
    "    ref_fr_dict = json.load(json_file)\n",
    "with open(data_path+'MMTtranslationdict_fr.json') as json_file:\n",
    "    mt_fr_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "une photo aérienne d'un paysage d'herbe brunissante avec une sorte de château culminant , et un paysage montagneux à l'horizon .\n",
      "\n",
      "une photo aérienne de seniors et d'une belle structure ressemblant à travers un paysage de montagne dans l'horizon.\n",
      "\n",
      "un paysage de signalisation, regarde de la prairie et une structure ressemblant à une structure à l'intérieur et un paysage de montagne à l'horizon.\n",
      "\n",
      "une photo de paysage aérienne d'une prairie et d'une structure ressemblant à une structure en hauteur et un paysage de montagne à l'horizon.\n",
      "\n",
      "une photo de pêcheurs aérienne de paille et d'une structure brumeuse regarde au loin et un paysage de montagne à l'horizon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_up_french(ref_fr_dict, mt_fr_dict):\n",
    "    tmp = ref_fr_dict.items()\n",
    "    for key, value in tmp:\n",
    "        new_val = re.sub(r\"&\\w+;\\s\",\"'\",value)\n",
    "        ref_fr_dict[key] = new_val\n",
    "\n",
    "    tmp = mt_fr_dict.items()\n",
    "    for key, value in tmp:\n",
    "            new_val = [[re.sub(r\"&\\w+;\\s\",\"'\",item[0]),item[1]]for item in value]\n",
    "            mt_fr_dict[key] = new_val\n",
    "    return ref_fr_dict, mt_fr_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "ref_fr_dict, mt_fr_dict = clean_up_french(ref_fr_dict, mt_fr_dict)\n",
    "    \n",
    "# print(ref_fr_dict[\"30167206992.jpg\"])\n",
    "# print(mt_fr_dict[\"30167206992.jpg\"])\n",
    "\n",
    "print(ref_fr_dict[\"27124904596.jpg\"])\n",
    "print()\n",
    "for i in mt_fr_dict[\"27124904596.jpg\"]:\n",
    "    print(i[0]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# matching image id for src sent, ref sent, translation sent\n",
    "\n",
    "## Sorting if necessary\n",
    "# sorted_src_dict = {key: value for key, value in sorted(src_dict.items(), key=lambda item: item[0])}\n",
    "# ref_de_dict = {key: value for key, value in sorted(ref_de_dict.items(), key=lambda item: item[0])}\n",
    "# score_de_dict = {key: value for key, value in sorted(score_de_dict.items(), key=lambda item: item[0])}\n",
    "\n",
    "de_match = {}\n",
    "assert len(src_dict) == len(ref_de_dict)\n",
    "for src_id in src_dict:\n",
    "    if src_id in mt_de_dict and src_id in ref_de_dict:\n",
    "         de_match[src_id] = [src_dict[src_id], ref_de_dict[src_id], mt_de_dict[src_id]]\n",
    "    else:\n",
    "        de_match[src_id] = [src_dict[src_id], ref_de_dict[src_id], []] # Assign empty list for Non-score sentences\n",
    "print(len(de_match))\n",
    "\n",
    "\n",
    "fr_match = {}\n",
    "assert len(src_dict) == len(ref_fr_dict)\n",
    "for src_id in src_dict:\n",
    "    if src_id in mt_fr_dict and src_id in ref_fr_dict:\n",
    "         fr_match[src_id] = [src_dict[src_id], ref_fr_dict[src_id], mt_fr_dict[src_id]]\n",
    "    else:\n",
    "        fr_match[src_id] = [src_dict[src_id], ref_fr_dict[src_id], []]\n",
    "print(len(fr_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all sentence data from dictionaries\n",
    "\n",
    "#1. source sentences in English\n",
    "src_sent = [item[0] for item in de_match.values()]\n",
    "\n",
    "#2. reference German sentences\n",
    "ref_de_sent = [item[1] for item in de_match.values()]\n",
    "\n",
    "#3. reference french sentences\n",
    "ref_fr_sent = [item[1] for item in fr_match.values()]\n",
    "\n",
    "#4. translation score on German sentences\n",
    "mt_de = [item[2] for item in de_match.values()]\n",
    "        \n",
    "#5. translation score on French sentences\n",
    "mt_fr = [item[2] for item in fr_match.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert fr, de source order are the same\n",
    "assert list(fr_match.keys()) == list(de_match.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence preprocessing on source sentences\n",
    "# {img_id: [preprocessed tokens ... ]}\n",
    "\n",
    "def data_processing(src_sents, tokenizer, stop_words=None, MT=False):    \n",
    "    token_sents = []\n",
    "    \n",
    "    for i in range(len(src_sents)): \n",
    "        if MT: \n",
    "            sent = src_sents[i][0]\n",
    "        else:\n",
    "            sent = src_sents[i]\n",
    "            \n",
    "#         sent = sent.lower() \n",
    "        word_list = tokenizer.tokenize(sent) # Tokenizer\n",
    "#       word_list = [w for w in word_list if not w in stop_words] # stop words removal\n",
    "#         word_list = [w for w in word_list if w.isalnum()] # punct_filtered\n",
    "\n",
    "        #stemming\n",
    "        # stemmer = SnowballStemmer('english')\n",
    "        # sentence_stemmed = []\n",
    "        # for token in punct_filtered:\n",
    "        #     sentence_stemmed.append(stemmer.stem(token))\n",
    "        \n",
    "        if MT: \n",
    "            token_sents.append([word_list, src_sents[i][1]])\n",
    "        else:    \n",
    "            token_sents.append(word_list)\n",
    " \n",
    "    return token_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=False)\n",
    "\n",
    "img_ids = list(src_dict.keys())\n",
    "\n",
    "src_tokens= {idx: val for idx, val in zip(img_ids, data_processing(src_sent, bert_tokenizer))}\n",
    "ref_de_tokens = {idx: val for idx, val in zip(img_ids, data_processing(ref_de_sent, bert_tokenizer))}\n",
    "ref_fr_tokens = {idx: val for idx, val in zip(img_ids, data_processing(ref_fr_sent, bert_tokenizer))}\n",
    "\n",
    "mt_fr_tokens = {idx:data_processing(fr_sent, bert_tokenizer, MT=True) for idx, fr_sent in zip(img_ids,mt_fr)}\n",
    "mt_de_tokens = {idx:data_processing(de_sent, bert_tokenizer, MT=True) for idx, de_sent in zip(img_ids, mt_de)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id: 25622467670.jpg\n",
      "\n",
      "Original source sentence:\n",
      "privately owned poster and restaurant poster\n",
      "\n",
      "Tokenized source sentence:\n",
      "['privately', 'owned', 'poster', 'and', 'restaurant', 'poster']\n",
      "\n",
      "Original reference German sentence:\n",
      "schild für privatbesitz und schild eines restaurants\n",
      "\n",
      "Tokenized reference German sentence:\n",
      "['s', '##child', 'für', 'privat', '##besitz', 'und', 's', '##child', 'eines', 'restaurants']\n",
      "\n",
      "Original reference French sentence:\n",
      "une pancarte 'propriété privée 'et un panneau pour un restaurant\n",
      "\n",
      "Tokenized reference French sentence:\n",
      "['une', 'pan', '##car', '##te', \"'\", 'propriété', 'privée', \"'\", 'et', 'un', 'pan', '##neau', 'pour', 'un', 'restaurant']\n",
      "\n",
      "[['une affiche aveuse et un restaurant .', -1.60627323003466], ['une maison apprenant à une affiche de restaurant et une affiche de restaurant', -0.351114913586192], ['une affiche et des', -1.60795922940204]]\n",
      "[[['une', 'affiche', 'ave', '##use', 'et', 'un', 'restaurant', '.'], -1.60627323003466], [['une', 'maison', 'app', '##rena', '##nt', 'à', 'une', 'affiche', 'de', 'restaurant', 'et', 'une', 'affiche', 'de', 'restaurant'], -0.351114913586192], [['une', 'affiche', 'et', 'des'], -1.60795922940204]]\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "\n",
    "i = 30\n",
    "img_id = img_ids[i]\n",
    "print(f\"Image id: {img_id}\\n\")\n",
    "print(f\"Original source sentence:\\n{src_sent[i]}\\n\")\n",
    "print(f\"Tokenized source sentence:\\n{src_tokens[img_id]}\\n\")\n",
    "print(f\"Original reference German sentence:\\n{ref_de_sent[i]}\\n\")\n",
    "print(f\"Tokenized reference German sentence:\\n{ref_de_tokens[img_id]}\\n\")\n",
    "print(f\"Original reference French sentence:\\n{ref_fr_sent[i]}\\n\")\n",
    "print(f\"Tokenized reference French sentence:\\n{ref_fr_tokens[img_id]}\\n\")\n",
    "\n",
    "print(mt_fr[i])\n",
    "print(mt_fr_tokens[img_id])\n",
    "\n",
    "\n",
    "for i in range(len(src_sent)):\n",
    "    assert src_sent[i] == src_dict[img_ids[i]]\n",
    "    assert ref_fr_sent[i] == ref_fr_dict[img_ids[i]]\n",
    "    if len(mt_fr[i]) > 0:\n",
    "        assert mt_fr[i] == mt_fr_dict[img_ids[i]]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"ein schwarz-weiß-foto eines hundes , der nach vorn blickt , mit einem hintergrund aus schildern in einer asiatischen sprache .\"\n",
    "# print(bert_tokenizer.tokenize(s))\n",
    "# s = \"une photo noire et blanc d&apos; un chien regardant devant un chien de panneaux en arrière @-@ plan .\"\n",
    "# print(bert_tokenizer.tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k =0\n",
    "# for i in ref_fr_sent[:100]:\n",
    "#     print(k)\n",
    "#     r1 = re.findall(r\"&\\w+;\",i)\n",
    "#     if len(r1)>0:\n",
    "#         print(r1)\n",
    "#     k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"un lac paisible entouré d&apos; arbres et des rochers .\"\n",
    "# r1 = re.sub(r\"&\\w+;\\s\",\"'\",s)\n",
    "# print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMD with Bert embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Using GPU: False\n"
     ]
    }
   ],
   "source": [
    "use_GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_GPU else \"cpu\")\n",
    "print('Device: ' + str(device))\n",
    "if use_GPU:\n",
    "    torch.cuda.manual_seed(0)\n",
    "    print('GPU: ' + str(torch.cuda.get_device_name(int(\"0\")))) \n",
    "print(\"Using GPU: {}\".format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=False)\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bert_tokenization(txt, tokenizer):\n",
    "\n",
    "# #     indexed_tokens = []\n",
    "# #     tokenized_text = []\n",
    "# #     segments_ids = []\n",
    "\n",
    "# #     for i in range(len(marked_text_en)):\n",
    "\n",
    "# #         txt = \"[CLS] \"+ marked_text_en[i] +\" [SEP] \" + marked_text_zh[i] + \" [SEP]\"\n",
    "# #         tokens = tokenizer.tokenize(txt)\n",
    "\n",
    "# #         tmp = tokens.index(\"[SEP]\")\n",
    "# #         sep1 = [0]*(tmp+1)\n",
    "# #         sep2 = [1]*(len(tokens)-tmp - 1)\n",
    "# #         segments_ids.append(torch.tensor([sep1+sep2]))\n",
    "\n",
    "# #         tokenized_text.append(tokens)\n",
    "# #         indexed_tokens.append(torch.tensor([tokenizer.convert_tokens_to_ids(tokens)]))\n",
    "\n",
    "#     raw_tokens = []\n",
    "#     indexed_tokens = []\n",
    "#     segments_ids = []\n",
    "    \n",
    "#     for sent in txt:\n",
    "#         raw = tokenizer.tokenize(sent)\n",
    "#         tokens = [\"[CLS]\"] + raw\n",
    "#         raw_tokens.append(raw)\n",
    "#         indexed_tokens.append(torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0))\n",
    "#         segments_ids.append(torch.tensor([0]*len(tokens)).unsqueeze(0))\n",
    "\n",
    "#     return raw_tokens, indexed_tokens, segments_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bertProcessing(indexed_tokens,segments_ids, model):\n",
    "\n",
    "#     sentences_embedding = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for i in range(len(indexed_tokens)):\n",
    "\n",
    "#             # \"encoded_layers\" has shape [12 x 1 x N x 768]\n",
    "\n",
    "#             encoded_layers, _ = model(indexed_tokens[i], segments_ids[i])\n",
    "\n",
    "#             token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "#             token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "#             token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "#             # \"token_embeddings\" has shape [N x 12 x 768]\n",
    "\n",
    "#             token_vecs_sum = []\n",
    "\n",
    "#             for token in token_embeddings:\n",
    "                \n",
    "#                 sum_vec = torch.sum(token[-4:],dim=0)\n",
    "#                 token_vecs_sum.append(sum_vec)\n",
    "\n",
    "#             # \"token_vecs\" is a tensor with shape [N x 768]\n",
    "#             token_vecs = torch.stack(token_vecs_sum,dim=0)\n",
    "\n",
    "#             sentences_embedding.append(token_vecs.cpu().detach().numpy())\n",
    "#                 # Calculate the average of all N token vectors.        \n",
    "# #                 sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "# #                 sentences_embedding.append(sentence_embedding.cpu().detach().numpy())\n",
    "# #             print(len(token_vecs_sum))\n",
    "            \n",
    "# #     return np.array(sentences_embedding, dtype=np.float32)\n",
    "#     return sentences_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenization(txt, tokenizer):\n",
    "    \n",
    "    tokens = tokenizer.tokenize(\"[CLS] \" + txt+ \" [SEP]\")\n",
    "    \n",
    "    indexed_tokens= torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
    "    segments_ids = torch.tensor([0]*len(tokens)).unsqueeze(0)\n",
    "\n",
    "    return tokens[1:-1], indexed_tokens, segments_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_processing(indexed_tokens,segments_ids, model):\n",
    "\n",
    "#     sentences_embedding = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "#         for i in range(len(indexed_tokens)):\n",
    "\n",
    "        # \"encoded_layers\" has shape [12 x 1 x N x 768]\n",
    "\n",
    "        encoded_layers, _ = model(indexed_tokens, segments_ids)\n",
    "\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "        # \"token_embeddings\" has shape [N x 12 x 768]\n",
    "\n",
    "        token_vecs_sum = []\n",
    "\n",
    "        for token in token_embeddings:\n",
    "#             sum_vec = torch.tensor(token[-1,:])\n",
    "#             sum_vec = torch.tensor(gen_mean(token, 1))\n",
    "#             sum_vec = torch.mean(token[-5:,], dim=0)\n",
    "            sum_vec = get_layer_embedding(token[-5:,], [\"min\",\"mean\",\"max\"])\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "\n",
    "        # \"token_vecs\" is a tensor with shape [N x 768]\n",
    "        \n",
    "        token_vecs = torch.stack(token_vecs_sum, dim=0)\n",
    "\n",
    "#         sentences_embedding.append(token_vecs.cpu().detach().numpy())\n",
    "\n",
    "            # Calculate the average of all N token vectors.        \n",
    "#                 sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "#                 sentences_embedding.append(sentence_embedding.cpu().detach().numpy())\n",
    "#             print(len(token_vecs_sum))\n",
    "\n",
    "#     return np.array(sentences_embedding, dtype=np.float32)\n",
    "    return token_vecs[1:-1,:]\n",
    "#     return encoded_layers[-1].squeeze(0)[1:-1,:]\n",
    "#     return token_embeddings[1:-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mean(vals, p):\n",
    "    p = float(p)\n",
    "    return torch.pow(torch.mean(torch.pow(torch.tensor(vals),p),dim=0),1 / p)   \n",
    "\n",
    "operations = dict([\n",
    "    ('mean', (lambda word_embeddings: [torch.mean(word_embeddings, dim=0)], lambda embeddings_size: embeddings_size)),\n",
    "    ('max', (lambda word_embeddings: torch.max(word_embeddings, dim=0), lambda embeddings_size: embeddings_size)),\n",
    "    ('min', (lambda word_embeddings: torch.min(word_embeddings, dim=0), lambda embeddings_size: embeddings_size)),\n",
    "    ('p_mean_2', (lambda word_embeddings: [gen_mean(word_embeddings, p=2.0)], lambda embeddings_size: embeddings_size)),\n",
    "    ('p_mean_3', (lambda word_embeddings: [gen_mean(word_embeddings, p=3.0)], lambda embeddings_size: embeddings_size)),\n",
    "])\n",
    "\n",
    "\n",
    "def get_layer_embedding(word_embeddings, chosen_operations):\n",
    "\n",
    "    concat_embs = []\n",
    "    for o in chosen_operations:\n",
    "        concat_embs += operations[o][0](word_embeddings)\n",
    "        \n",
    "    layer_embedding = np.concatenate(\n",
    "        concat_embs,\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    return torch.tensor(layer_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 3840])\n"
     ]
    }
   ],
   "source": [
    "ref_tokens, ref_id, ref_seg = bert_tokenization(ref_de_sent[0], bert_tokenizer)\n",
    "output = bert_processing(ref_id, ref_seg, model)\n",
    "print(output.size())\n",
    "\n",
    "# embed = get_layer_embedding(output[0],[\"min\",\"mean\",\"max\"])\n",
    "# print(embed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ein schlanker gelblicher hund beim absolvieren eines hindernislaufs , der in einem bereich mit nacktem erdboden aufgebaut ist\n",
      "['ein', 's', '##ch', '##lank', '##er', 'gel', '##bliche', '##r', 'hun', '##d', 'beim', 'ab', '##sol', '##vieren', 'eines', 'hin', '##dern', '##is', '##lauf', '##s', ',', 'der', 'in', 'einem', 'bere', '##ich', 'mit', 'na', '##ckte', '##m', 'er', '##d', '##boden', 'aufgebaut', 'ist']\n",
      "35\n",
      "torch.Size([35, 12, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yurunsong/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/yurunsong/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "# ref_tokens, ref_id, ref_seg = bert_tokenization(ref_de_sent[0], bert_tokenizer)\n",
    "# output = bert_processing(ref_id, ref_seg, model)\n",
    "# print(len(ref_tokens))\n",
    "# print(output)\n",
    "# out = model.embeddings.word_embeddings(ref_id)\n",
    "# print(out)\n",
    "# wordvecs = {token: embedding.detach().numpy() for token, embedding in zip(ref_tokens, output[1:,:])}\n",
    "# # print(wordvecs['ein'])\n",
    "\n",
    "ref_tokens, ref_id, ref_seg = bert_tokenization(ref_de_sent[0], bert_tokenizer)\n",
    "output = bert_processing(ref_id, ref_seg, model)\n",
    "    \n",
    "print(ref_de_sent[0])\n",
    "print(ref_tokens)\n",
    "print(len(ref_tokens))\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "20\n",
      "torch.Size([42, 768])\n",
      "tensor([[-0.1536, -0.0189,  0.2071,  ...,  1.1515,  0.8207, -0.6571],\n",
      "        [ 0.2179,  0.1744, -0.6390,  ...,  1.0593,  0.7526, -0.2311],\n",
      "        [ 0.4040, -0.0304, -0.5294,  ...,  1.3307,  0.8977, -0.4279],\n",
      "        ...,\n",
      "        [ 0.0501, -0.3016,  0.3218,  ...,  0.4733,  0.2745,  0.6326],\n",
      "        [-0.1850, -0.3029, -0.1762,  ...,  0.4389,  0.6060,  0.6113],\n",
      "        [-0.3669, -0.5658,  1.0363,  ...,  0.1708,  0.5354,  0.2067]])\n"
     ]
    }
   ],
   "source": [
    "# s1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "# s2 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "\n",
    "# first_sent_tokens, first_id, first_seg  = bert_tokenization(s1, bert_tokenizer)\n",
    "# second_sent_tokens, second_id, second_seg = bert_tokenization(s2, bert_tokenizer)\n",
    "\n",
    "# first_sent_buckets = tokens_to_fracdict_contextual(first_sent_tokens)\n",
    "# second_sent_buckets = tokens_to_fracdict_contextual(second_sent_tokens)\n",
    "\n",
    "# first_sent_embedding = bert_processing(first_id, first_seg, model)\n",
    "# second_sent_embedding = bert_processing(second_id, second_seg, model)\n",
    "\n",
    "# all_embedding = torch.cat([first_sent_embedding, second_sent_embedding])\n",
    "\n",
    "# assert len(first_sent_buckets) + len(second_sent_buckets) == all_embedding.size()[0]\n",
    "# print(len(first_sent_buckets))\n",
    "# print(len(second_sent_buckets))\n",
    "# print(all_embedding.size())\n",
    "# print(all_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Natural Language Toolkit: Machine Translation\n",
    "#\n",
    "# Copyright (C) 2001-2020 NLTK Project\n",
    "# Author: Uday Krishna <udaykrishna5@gmail.com>\n",
    "# URL: <http://nltk.org/>\n",
    "# For license information, see LICENSE.TXT\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain, product\n",
    "\n",
    "def _generate_enums(hypothesis, reference, preprocess=str.lower):\n",
    "    \"\"\"\n",
    "    Takes in string inputs for hypothesis and reference and returns\n",
    "    enumerated word lists for each of them\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :preprocess: preprocessing method (default str.lower)\n",
    "    :type preprocess: method\n",
    "    :return: enumerated words list\n",
    "    :rtype: list of 2D tuples, list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list = list(enumerate(preprocess(hypothesis).split()))\n",
    "    reference_list = list(enumerate(preprocess(reference).split()))\n",
    "    return hypothesis_list, reference_list\n",
    "\n",
    "\n",
    "def exact_match(hypothesis, reference):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference\n",
    "    and returns a word mapping based on the enumerated\n",
    "    word id between hypothesis and reference\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :type hypothesis: str\n",
    "    :param reference: reference string\n",
    "    :type reference: str\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    hypothesis_list, reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _match_enums(hypothesis_list, reference_list)\n",
    "\n",
    "\n",
    "\n",
    "def _match_enums(enum_hypothesis_list, enum_reference_list):\n",
    "    \"\"\"\n",
    "    matches exact words in hypothesis and reference and returns\n",
    "    a word mapping between enum_hypothesis_list and enum_reference_list\n",
    "    based on the enumerated word id.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :type enum_hypothesis_list: list of tuples\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :type enum_reference_list: list of 2D tuples\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_hypothesis_list[i][1] == enum_reference_list[j][1]:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                (enum_hypothesis_list.pop(i)[1], enum_reference_list.pop(j)[1])\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def _enum_stem_match(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer()\n",
    "):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between enum_hypothesis_list and\n",
    "    enum_reference_list based on the enumerated word id. The function also\n",
    "    returns a enumerated list of unmatched words for hypothesis and reference.\n",
    "\n",
    "    :param enum_hypothesis_list:\n",
    "    :type enum_hypothesis_list:\n",
    "    :param enum_reference_list:\n",
    "    :type enum_reference_list:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    stemmed_enum_list1 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_hypothesis_list\n",
    "    ]\n",
    "\n",
    "    stemmed_enum_list2 = [\n",
    "        (word_pair[0], stemmer.stem(word_pair[1])) for word_pair in enum_reference_list\n",
    "    ]\n",
    "\n",
    "    word_match, enum_unmat_hypo_list, enum_unmat_ref_list = _match_enums(\n",
    "        stemmed_enum_list1, stemmed_enum_list2\n",
    "    )\n",
    "\n",
    "    enum_unmat_hypo_list = (\n",
    "        list(zip(*enum_unmat_hypo_list)) if len(enum_unmat_hypo_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_unmat_ref_list = (\n",
    "        list(zip(*enum_unmat_ref_list)) if len(enum_unmat_ref_list) > 0 else []\n",
    "    )\n",
    "\n",
    "    enum_hypothesis_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_hypo_list, enum_hypothesis_list)\n",
    "    )\n",
    "\n",
    "    enum_reference_list = list(\n",
    "        filter(lambda x: x[0] not in enum_unmat_ref_list, enum_reference_list)\n",
    "    )\n",
    "\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def stem_match(hypothesis, reference, stemmer=PorterStemmer()):\n",
    "    \"\"\"\n",
    "    Stems each word and matches them in hypothesis and reference\n",
    "    and returns a word mapping between hypothesis and reference\n",
    "\n",
    "    :param hypothesis:\n",
    "    :type hypothesis:\n",
    "    :param reference:\n",
    "    :type reference:\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that\n",
    "                   implements a stem method\n",
    "    :return: enumerated matched tuples, enumerated unmatched hypothesis tuples,\n",
    "             enumerated unmatched reference tuples\n",
    "    :rtype: list of 2D tuples, list of 2D tuples,  list of 2D tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_stem_match(enum_hypothesis_list, enum_reference_list, stemmer=stemmer)\n",
    "\n",
    "\n",
    "\n",
    "def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis\n",
    "    if any synonym of a hypothesis word is the exact match\n",
    "    to the reference word.\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype:  list of tuples, list of tuples, list of tuples\n",
    "\n",
    "    \"\"\"\n",
    "    word_match = []\n",
    "    for i in range(len(enum_hypothesis_list))[::-1]:\n",
    "        hypothesis_syns = set(\n",
    "            chain(\n",
    "                *[\n",
    "                    [\n",
    "                        lemma.name()\n",
    "                        for lemma in synset.lemmas()\n",
    "                        if lemma.name().find(\"_\") < 0\n",
    "                    ]\n",
    "                    for synset in wordnet.synsets(enum_hypothesis_list[i][1])\n",
    "                ]\n",
    "            )\n",
    "        ).union({enum_hypothesis_list[i][1]})\n",
    "        for j in range(len(enum_reference_list))[::-1]:\n",
    "            if enum_reference_list[j][1] in hypothesis_syns:\n",
    "                word_match.append(\n",
    "                    (enum_hypothesis_list[i][0], enum_reference_list[j][0])\n",
    "                )\n",
    "                enum_hypothesis_list.pop(i), enum_reference_list.pop(j)\n",
    "                break\n",
    "    return word_match, enum_hypothesis_list, enum_reference_list\n",
    "\n",
    "\n",
    "def wordnetsyn_match(hypothesis, reference, wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Matches each word in reference to a word in hypothesis if any synonym\n",
    "    of a hypothesis word is the exact match to the reference word.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: list of mapped tuples\n",
    "    :rtype: list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _enum_allign_words(\n",
    "    enum_hypothesis_list, enum_reference_list, stemmer=PorterStemmer(), wordnet=wordnet\n",
    "):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    in case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen. Takes enumerated list as input instead of\n",
    "    string input\n",
    "\n",
    "    :param enum_hypothesis_list: enumerated hypothesis list\n",
    "    :param enum_reference_list: enumerated reference list\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list,\n",
    "             unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    exact_matches, enum_hypothesis_list, enum_reference_list = _match_enums(\n",
    "        enum_hypothesis_list, enum_reference_list\n",
    "    )\n",
    "\n",
    "    stem_matches, enum_hypothesis_list, enum_reference_list = _enum_stem_match(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer\n",
    "    )\n",
    "\n",
    "    wns_matches, enum_hypothesis_list, enum_reference_list = _enum_wordnetsyn_match(\n",
    "        enum_hypothesis_list, enum_reference_list, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        sorted(\n",
    "            exact_matches + stem_matches + wns_matches, key=lambda wordpair: wordpair[0]\n",
    "        ),\n",
    "        enum_hypothesis_list,\n",
    "        enum_reference_list,\n",
    "    )\n",
    "\n",
    "\n",
    "def allign_words(hypothesis, reference, stemmer=PorterStemmer(), wordnet=wordnet):\n",
    "    \"\"\"\n",
    "    Aligns/matches words in the hypothesis to reference by sequentially\n",
    "    applying exact match, stemmed match and wordnet based synonym match.\n",
    "    In case there are multiple matches the match which has the least number\n",
    "    of crossing is chosen.\n",
    "\n",
    "    :param hypothesis: hypothesis string\n",
    "    :param reference: reference string\n",
    "    :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer())\n",
    "    :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method\n",
    "    :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet)\n",
    "    :type wordnet: WordNetCorpusReader\n",
    "    :return: sorted list of matched tuples, unmatched hypothesis list, unmatched reference list\n",
    "    :rtype: list of tuples, list of tuples, list of tuples\n",
    "    \"\"\"\n",
    "    enum_hypothesis_list, enum_reference_list = _generate_enums(hypothesis, reference)\n",
    "    return _enum_allign_words(\n",
    "        enum_hypothesis_list, enum_reference_list, stemmer=stemmer, wordnet=wordnet\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _count_chunks(matches):\n",
    "    \"\"\"\n",
    "    Counts the fewest possible number of chunks such that matched unigrams\n",
    "    of each chunk are adjacent to each other. This is used to caluclate the\n",
    "    fragmentation part of the metric.\n",
    "\n",
    "    :param matches: list containing a mapping of matched words (output of allign_words)\n",
    "    :return: Number of chunks a sentence is divided into post allignment\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    chunks = 1\n",
    "    while i < len(matches) - 1:\n",
    "        if (matches[i + 1][0] == matches[i][0] + 1) and (\n",
    "            matches[i + 1][1] == matches[i][1] + 1\n",
    "        ):\n",
    "            i += 1\n",
    "            continue\n",
    "        i += 1\n",
    "        chunks += 1\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "def penalty(    \n",
    "    reference,\n",
    "    hypothesis,\n",
    "    preprocess=str.lower,\n",
    "    stemmer=PorterStemmer(),\n",
    "    wordnet=wordnet):\n",
    "    \n",
    "    enum_hypothesis, enum_reference = _generate_enums(\n",
    "        hypothesis, reference, preprocess=preprocess\n",
    "    )\n",
    "    \n",
    "    translation_length = len(enum_hypothesis)\n",
    "    reference_length = len(enum_reference)\n",
    "    \n",
    "    matches, _, _ = _enum_allign_words(enum_hypothesis, enum_reference, stemmer=stemmer)\n",
    "    \n",
    "    matches_count = len(matches)\n",
    "    \n",
    "    try:\n",
    "        chunk_count = float(_count_chunks(matches))\n",
    "        frag_frac = chunk_count / matches_count\n",
    "        \n",
    "    except ZeroDivisionError: # No unigrams match\n",
    "        return 0\n",
    "    \n",
    "    return frag_frac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert-embedding\n",
    "# If you want to run on GPU machine, please install `mxnet-cu92`.\n",
    "# pip install mxnet-cu92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_fracdict_contextual(tokens):\n",
    "    \n",
    "    return {token: 1/len(tokens) for token in range(len(tokens))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_fracdict(tokens):\n",
    "    cntdict = defaultdict(lambda : 0)\n",
    "    for token in tokens:\n",
    "        cntdict[token] += 1\n",
    "    totalcnt = sum(cntdict.values())\n",
    "    return {token: float(cnt)/totalcnt for token, cnt in cntdict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_mover_distance_probspec_bert(first_sent, second_sent, lpFile=None):\n",
    "    \n",
    "#     first_sent_tokens  = bert_tokenizer.tokenize(first_sent)\n",
    "#     second_sent_tokens = bert_tokenizer.tokenize(second_sent)\n",
    "    \n",
    "#     first_sent_buckets = tokens_to_fracdict(first_sent_tokens)\n",
    "#     second_sent_buckets = tokens_to_fracdict(second_sent_tokens)\n",
    "    \n",
    "#     first_sent_embedding = model.embeddings.word_embeddings(torch.tensor(bert_tokenizer.convert_tokens_to_ids(list(first_sent_buckets.keys()))))\n",
    "#     second_sent_embedding = model.embeddings.word_embeddings(torch.tensor(bert_tokenizer.convert_tokens_to_ids(list(second_sent_buckets.keys()))))\n",
    "    \n",
    "#     all_embedding = torch.cat([first_sent_embedding, second_sent_embedding])\n",
    "    \n",
    "    first_sent_tokens, first_id, first_seg  = bert_tokenization(first_sent, bert_tokenizer)\n",
    "    second_sent_tokens, second_id, second_seg = bert_tokenization(second_sent, bert_tokenizer)\n",
    "    \n",
    "    first_sent_buckets = tokens_to_fracdict_contextual(first_sent_tokens)\n",
    "    second_sent_buckets = tokens_to_fracdict_contextual(second_sent_tokens)\n",
    "    \n",
    "    first_sent_embedding = bert_processing(first_id, first_seg, model)\n",
    "    second_sent_embedding = bert_processing(second_id, second_seg, model)\n",
    "    \n",
    "    all_embedding = torch.cat([first_sent_embedding, second_sent_embedding])\n",
    "    \n",
    "    assert len(first_sent_buckets) + len(second_sent_buckets) == all_embedding.size()[0]\n",
    "\n",
    "    # Updated buckets with labeled name\n",
    "    first_sent_buckets = {f\"x{idx}\": item[1] for idx, item in enumerate(first_sent_buckets.items())}\n",
    "    second_sent_buckets = {f\"y{idx}\": item[1] for idx, item in enumerate(second_sent_buckets.items())}\n",
    "\n",
    "    var_names = list(first_sent_buckets.keys()) + list(second_sent_buckets.keys())\n",
    "    \n",
    "    wordvecs = {token: embedding.detach().numpy() for token, embedding in zip(var_names, all_embedding)}\n",
    "    \n",
    "    T = pulp.LpVariable.dicts('T_matrix', list(product(var_names, var_names)), lowBound=0)\n",
    "\n",
    "    prob = pulp.LpProblem('WMD', sense=pulp.LpMinimize)\n",
    "    \n",
    "    prob += pulp.lpSum([T[token1, token2]*euclidean(wordvecs[token1], wordvecs[token2])\n",
    "                        for token1, token2 in product(var_names, var_names)])\n",
    "    \n",
    "    for token2 in second_sent_buckets:   #constrains\n",
    "        prob += pulp.lpSum([T[token1, token2] for token1 in first_sent_buckets])==second_sent_buckets[token2]\n",
    "        \n",
    "    for token1 in first_sent_buckets:    #constrains\n",
    "        prob += pulp.lpSum([T[token1, token2] for token2 in second_sent_buckets])==first_sent_buckets[token1]\n",
    "\n",
    "    if lpFile!=None:\n",
    "        prob.writeLP(lpFile)\n",
    "\n",
    "    prob.solve()\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_mover_distance(first_sent, second_sent, lpFile=None):\n",
    "    prob = word_mover_distance_probspec_bert(first_sent, second_sent, lpFile=lpFile)\n",
    "    return pulp.value(prob.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluency_based_wmd(wmd, ref, hypo, gamma=0.2):\n",
    "    frag_penalty = penalty(ref, hypo)\n",
    "#     print(frag_penalty)\n",
    "    return wmd - gamma *(0.5 - frag_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypo = word_tokenize(\"eine luftaufnahme mit braun werdenden bäumen , einem schlossartigen gebäude , das darin zu erkennen ist , und einer berglandschaft am horizont .\")\n",
    "# ref = word_tokenize(\"ein aerielles land , das ein foto von einer braunen wiese und einer kastenähnlichen struktur , die durch und eine berglandschaft im horizont fährt .\")\n",
    "# print(penalty(ref, hypo))\n",
    "\n",
    "# s1 = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "# s2 = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "\n",
    "# s1='ein kleines mädchen , das an metallseilen hochklettert und einen langen rosafarbenen rock und ein schwarzes t-shirt trägt .'\n",
    "# s2='30115958512_13531ae2e8.jpg'\n",
    "# hypothesis1 = bert_tokenizer.tokenize(s1)\n",
    "# reference1 = bert_tokenizer.tokenize(s2)\n",
    "\n",
    "# first_sent_buckets = tokens_to_fracdict(hypothesis1)\n",
    "# print(sum(list(first_sent_buckets.values())))\n",
    "# print(list(product(hypothesis1, hypothesis1)))\n",
    "# output = word_mover_distance(hypothesis1, reference1, model.embeddings.word_embeddings)\n",
    "# print(output)\n",
    "# print(fluency_based_wmd(output, s2, s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "torch.Size([34, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yurunsong/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "ref_tokens, ref_id, ref_seg = bert_tokenization(ref_de_sent[0], bert_tokenizer)\n",
    "output = bert_processing(ref_id, ref_seg, model)\n",
    "print(len(ref_tokens))\n",
    "print(output[1:,:].shape)\n",
    "\n",
    "wordvecs = {token: embedding.detach().numpy() for token, embedding in zip(ref_tokens, output[1:,:])}\n",
    "# print(wordvecs['ein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mover_distance(src_sent[0], ref_de_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processing_sent(sent, tokenizer, stop_words=None): # Nothing needs to be done except tokenize\n",
    "#     tokens = tokenizer.tokenize(sent)\n",
    "    \n",
    "#     if stop_words:\n",
    "#         tokens = [w for w in tokens if not w in stop_words] # stop words removal\n",
    "\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_WMD_WMDo(ref_sent, mt_sent):\n",
    "    score = []\n",
    "    wmd = []\n",
    "    wmdo =[]\n",
    "\n",
    "    for i in range(len(ref_sent)):\n",
    "        ref = ref_sent[i]\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        for mt in mt_sent[i]:\n",
    "            if mt:\n",
    "                hypo = mt[0]\n",
    "                wmd_tmp = word_mover_distance(ref, hypo)\n",
    "                wmdo_tmp = fluency_based_wmd(wmd_tmp, ref, hypo)\n",
    "                score.append(mt[1])\n",
    "                wmd.append(wmd_tmp)\n",
    "                wmdo.append(wmdo_tmp)\n",
    "\n",
    "    return wmd, wmdo, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(wmd, wmdo, score):\n",
    "    pearson = stats.pearsonr(wmd, score)\n",
    "    pearson_o = stats.pearsonr(wmdo, score)\n",
    "    spearman = stats.spearmanr(wmd, score)\n",
    "    spearman_o = stats.spearmanr(wmdo, score)\n",
    "    print(\"Spearman Correlation:\", spearman, spearman_o)\n",
    "    print(\"Pearson Correlation:\", pearson, pearson_o)\n",
    "    return pearson, pearson_o, spearman, spearman_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(ref_de_sent, mt_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German\n",
      "Average WMD: 69.82060101541869\n",
      "Average WMDo: 69.83274644933235\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.5278941164078803, pvalue=2.612801686441741e-249) SpearmanrResult(correlation=-0.5282769306333015, pvalue=9.83698361221888e-250)\n",
      "Pearson Correlation: (-0.49723739156495117, 4.875633745809798e-217) (-0.49782647030802085, 1.2546071005640493e-217)\n"
     ]
    }
   ],
   "source": [
    "print(\"German\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd,wmdo,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German\n",
    "Average WMD: 14.753766380597177\n",
    "Average WMDo: 14.765911814511023\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5408051231338127, pvalue=6.357095597124554e-264) SpearmanrResult(correlation=-0.5415326261357368, pvalue=9.135718745372739e-265)\n",
    "Pearson Correlation: (-0.510550953962252, 1.196828835525081e-230) (-0.5128446747092898, 4.695107306853758e-233)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(ref_fr_sent, mt_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\n",
      "Average WMD: 0.7319957530829252\n",
      "Average WMDo: 0.7120559700721092\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.5062751155749577, pvalue=3.763877843459969e-164) SpearmanrResult(correlation=-0.5040075033227038, pvalue=1.816938744204804e-162)\n",
      "Pearson Correlation: (-0.4473760002698459, 2.760555486290685e-124) (-0.4744602912350891, 1.191233536508193e-141)\n"
     ]
    }
   ],
   "source": [
    "print(\"French\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd, wmdo, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(src_sent, mt_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German\n",
      "Average WMD: 18.4382787309031\n",
      "Average WMDo: 18.458505960141462\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.3877016178408453, pvalue=2.4103141446547815e-125) SpearmanrResult(correlation=-0.3911701079270888, pvalue=9.341434856987254e-128)\n",
      "Pearson Correlation: (-0.364916617965492, 3.281589659711399e-110) (-0.36689664795980625, 1.7732519688719853e-111)\n"
     ]
    }
   ],
   "source": [
    "print(\"German\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd, wmdo, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German\n",
    "Average WMD: 18.09473854506236\n",
    "Average WMDo: 18.11496577430075\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.3888220517112738, pvalue=4.038384914655043e-126) SpearmanrResult(correlation=-0.392272892331188, pvalue=1.5759215445413317e-128)\n",
    "Pearson Correlation: (-0.3663276677750607, 4.110186786086501e-111) (-0.3683403659547836, 2.0848261680513684e-112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\n",
      "Average WMD: 17.53394350971217\n",
      "Average WMDo: 17.554236278671606\n",
      "Spearman Correlation: SpearmanrResult(correlation=-0.4020773951383244, pvalue=1.507033645902963e-98) SpearmanrResult(correlation=-0.401837321865042, pvalue=2.0148546831306177e-98)\n",
      "Pearson Correlation: (-0.3328195942333609, 3.070678519709238e-66) (-0.3332514592822259, 2.0406688113651785e-66)\n"
     ]
    }
   ],
   "source": [
    "wmd, wmdo, score = compute_WMD_WMDo(src_sent, mt_fr)\n",
    "print(\"French\")\n",
    "print(f\"Average WMD: {sum(wmd)/len(wmd)}\")\n",
    "print(f\"Average WMDo: {sum(wmdo)/len(wmdo)}\")\n",
    "_,_,_,_ = evaluation(wmd, wmdo, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "French\n",
    "Average WMD: 16.756025627736054\n",
    "Average WMDo: 16.776318396695512\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.4053943918063674, pvalue=2.6600260870893543e-100) SpearmanrResult(correlation=-0.40493190729140627, pvalue=4.68312010089249e-100)\n",
    "Pearson Correlation: (-0.33575896893394214, 1.8781364785621477e-67) (-0.336184560252449, 1.2500334156210449e-67)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German\n",
    "Average WMD: 0.8017151844060595\n",
    "Average WMDo: 0.8138606183198965\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.510027610018138, pvalue=4.21218212891956e-230) SpearmanrResult(correlation=-0.5219619561321359, pvalue=8.359442710590678e-243)\n",
    "Pearson Correlation: (-0.5097357138311422, 8.489667305520433e-230) (-0.5263318452409811, 1.3893750874145238e-247)\n",
    "\n",
    "German\n",
    "Average WMD: 14.367619206327053\n",
    "Average WMDo: 14.37976464024086\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5346587049562512, pvalue=6.91048714368436e-257) SpearmanrResult(correlation=-0.5356639914422371, pvalue=4.996019991229222e-258)\n",
    "Pearson Correlation: (-0.5069348041812386, 6.833029708905972e-227) (-0.509505332886907, 1.4754286321864593e-229)\n",
    "\n",
    "German\n",
    "Average WMD: 8.694474627081824\n",
    "Average WMDo: 8.706620060995649\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5260365544473777, pvalue=2.937572648888105e-247) SpearmanrResult(correlation=-0.5275756933309976, pvalue=5.88269414423705e-249)\n",
    "Pearson Correlation: (-0.5076935027563036, 1.122537251992892e-227) (-0.5112707564139629, 2.1127845225063138e-231)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "French\n",
    "Average WMD: 0.6042960387747216\n",
    "Average WMDo: 0.5843552624270132\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5088781037811415, pvalue=4.238102393698617e-166) SpearmanrResult(correlation=-0.5095406311221526, pvalue=1.3444148923818223e-166)\n",
    "Pearson Correlation: (-0.4513739384178891, 9.4483659745375e-127) (-0.47538274489884846, 2.8612199431667316e-142)\n",
    "\n",
    "French\n",
    "Average WMD: 12.275622826948323\n",
    "Average WMDo: 12.25568304393746\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.49264666562512005, pvalue=3.2071764012749155e-154) SpearmanrResult(correlation=-0.4930769665866644, pvalue=1.5827540043178295e-154)\n",
    "Pearson Correlation: (-0.4295813360647007, 1.055442628944799e-113) (-0.43196050189980867, 4.414998254116758e-115)\n",
    "\n",
    "French\n",
    "Average WMD: 7.319957527622561\n",
    "Average WMDo: 7.300017744611744\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5062751155749577, pvalue=3.763877843459969e-164) SpearmanrResult(correlation=-0.5064425750293479, pvalue=2.823526062812762e-164)\n",
    "Pearson Correlation: (-0.44737600006571154, 2.7605562811962084e-124) (-0.4507366982577241, 2.3473130052334892e-126)\n",
    "    \n",
    "French\n",
    "Average WMD: 0.7319957530829252\n",
    "Average WMDo: 0.7120559700721092\n",
    "Spearman Correlation: SpearmanrResult(correlation=-0.5062751155749577, pvalue=3.763877843459969e-164) SpearmanrResult(correlation=-0.5040075033227038, pvalue=1.816938744204804e-162)\n",
    "Pearson Correlation: (-0.4473760002698459, 2.760555486290685e-124) (-0.4744602912350891, 1.191233536508193e-141)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_score = np.array(score)/np.sqrt(np.sum(np.array(score)**2))\n",
    "norm_wmd = np.array(wmd)/ np.sqrt(np.sum(np.array(wmd)**2))\n",
    "norm_wmdo = np.array(wmdo)/np.sqrt(np.sum(np.array(wmdo)**2))\n",
    "\n",
    "# wmd = np.array(wmd) - (sum(wmd)/len(wmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.scatter(np.array(score)[:200],wmd[:200])\n",
    "plt.scatter(norm_score,norm_wmd)\n",
    "plt.scatter(norm_score,norm_wmdo)\n",
    "# plt.xlim([-3,3])\n",
    "# plt.ylim([-1.5,1.5])\n",
    "plt.xlabel(\"human score\")\n",
    "plt.ylabel(\"Normalized WMD score\")\n",
    "plt.legend([\"wmd\", \"wmdo\"])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word_mover_distance_probspec_1(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=None):\n",
    "#     all_tokens = list(set(first_sent_tokens+second_sent_tokens))\n",
    "#     all_embedding = wvmodel(torch.tensor(bert_tokenizer.convert_tokens_to_ids(all_tokens))).detach().numpy()\n",
    "    \n",
    "#     wordvecs = {token: embedding for token, embedding in zip(all_tokens, all_embedding)}\n",
    "\n",
    "#     first_sent_buckets = tokens_to_fracdict(first_sent_tokens)\n",
    "#     second_sent_buckets = tokens_to_fracdict(second_sent_tokens)\n",
    "\n",
    "#     T = pulp.LpVariable.dicts('T_matrix', list(product(all_tokens, all_tokens)), lowBound=0)\n",
    "\n",
    "#     prob = pulp.LpProblem('WMD', sense=pulp.LpMinimize)\n",
    "#     prob += pulp.lpSum([T[token1, token2]*euclidean(wordvecs[token1], wordvecs[token2])\n",
    "#                         for token1, token2 in product(all_tokens, all_tokens)])\n",
    "#     for token2 in second_sent_buckets:\n",
    "#         prob += pulp.lpSum([T[token1, token2] for token1 in first_sent_buckets])==second_sent_buckets[token2]\n",
    "#     for token1 in first_sent_buckets:\n",
    "#         prob += pulp.lpSum([T[token1, token2] for token2 in second_sent_buckets])==first_sent_buckets[token1]\n",
    "\n",
    "#     if lpFile!=None:\n",
    "#         prob.writeLP(lpFile)\n",
    "\n",
    "#     prob.solve()\n",
    "\n",
    "#     return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1=\"une photo aérienne d'un paysage d'herbe brunissante avec une sorte de château culminant , et un paysage montagneux à l'horizon .\"\n",
    "# s2=\"un paysage de signalisation, regarde de la prairie et une structure ressemblant à une structure à l'intérieur et un paysage de montagne à l'horizon.\"\n",
    "# hypothesis1 = bert_tokenizer.tokenize(s1)\n",
    "# reference1 = bert_tokenizer.tokenize(s2)\n",
    "# print(hypothesis1)\n",
    "# print(reference1)\n",
    "# prob1 = word_mover_distance_probspec(hypothesis1, reference1, model.embeddings.word_embeddings)\n",
    "# print(pulp.value(prob1.objective))\n",
    "\n",
    "# prob2 = word_mover_distance_probspec_1(hypothesis1, reference1, model.embeddings.word_embeddings)\n",
    "# print(pulp.value(prob2.objective))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_mean(vals, p):\n",
    "#     p = float(p)\n",
    "#     return np.power(np.mean(np.power(np.array(vals, dtype=np.float32),p),axis=0),1 / p)   \n",
    "\n",
    "# operations = dict([\n",
    "#     ('mean', (lambda word_embeddings: [np.mean(word_embeddings, axis=0)], lambda embeddings_size: embeddings_size)),\n",
    "#     ('max', (lambda word_embeddings: [np.max(word_embeddings, axis=0)], lambda embeddings_size: embeddings_size)),\n",
    "#     ('min', (lambda word_embeddings: [np.min(word_embeddings, axis=0)], lambda embeddings_size: embeddings_size)),\n",
    "#     ('p_mean_2', (lambda word_embeddings: [gen_mean(word_embeddings, p=2.0).real], lambda embeddings_size: embeddings_size)),\n",
    "#     ('p_mean_3', (lambda word_embeddings: [gen_mean(word_embeddings, p=3.0).real], lambda embeddings_size: embeddings_size)),\n",
    "# ])\n",
    "\n",
    "\n",
    "# def get_sentence_embedding(sentence, embeddings, chosen_operations):\n",
    "#     word_embeddings = []\n",
    "#     for tok in sentence:\n",
    "#         vec = embeddings.vectors.get(tok)\n",
    "#         if vec is not None:\n",
    "#             word_embeddings.append(vec)\n",
    "\n",
    "#     if not word_embeddings:\n",
    "#         print('No word embeddings for sentence:\\n{}'.format(sentence))\n",
    "#         size = 0\n",
    "#         for o in chosen_operations:\n",
    "#             size += operations[o][1](embeddings.embeddings_dimensionality)\n",
    "#         sentence_embedding = np.zeros(size)\n",
    "#     else:\n",
    "#         concat_embs = []\n",
    "#         for o in chosen_operations:\n",
    "#             concat_embs += operations[o][0](word_embeddings)\n",
    "#         sentence_embedding = np.concatenate(\n",
    "#             concat_embs,\n",
    "#             axis=0\n",
    "#         )\n",
    "\n",
    "#     return sentence_embedding    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
